{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocessing.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"aqswqyzCBl11","colab_type":"code","outputId":"3017abab-bd34-4708-9810-7c508f42f9ec","executionInfo":{"status":"ok","timestamp":1554444632385,"user_tz":-480,"elapsed":18475,"user":{"displayName":"Wei Han Chua","photoUrl":"","userId":"05534555087765695301"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"cell_type":"code","source":["# restart kernel after running this cell\n","!pip install pandas --upgrade"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pandas\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n","\u001b[K    100% |████████████████████████████████| 10.1MB 3.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n","Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n","\u001b[31mfastai 1.0.51 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n","Installing collected packages: pandas\n","  Found existing installation: pandas 0.22.0\n","    Uninstalling pandas-0.22.0:\n","      Successfully uninstalled pandas-0.22.0\n","Successfully installed pandas-0.24.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pandas"]}}},"metadata":{"tags":[]}}]},{"metadata":{"id":"fIFW9iPEA8u3","colab_type":"code","outputId":"2768e31f-a177-4e0f-e869-0230ae859bc5","executionInfo":{"status":"ok","timestamp":1554444691972,"user_tz":-480,"elapsed":37418,"user":{"displayName":"Wei Han Chua","photoUrl":"","userId":"05534555087765695301"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LinearRegression\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn import metrics\n","from bs4 import BeautifulSoup\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import LabelEncoder\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","import os\n","import glob\n","import re\n","import math\n","import json\n","import random\n","\n","from IPython import display\n","from matplotlib import cm\n","\n","import tensorflow as tf\n","from tensorflow.python.data import Dataset\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"GrV8E1y8A_nj","colab_type":"code","outputId":"5159a808-8586-4f3e-e404-8bc3e36e31c5","executionInfo":{"status":"error","timestamp":1554444696875,"user_tz":-480,"elapsed":1659,"user":{"displayName":"Wei Han Chua","photoUrl":"","userId":"05534555087765695301"}},"colab":{"base_uri":"https://localhost:8080/","height":2849}},"cell_type":"code","source":["%%time\n","\n","news_train_df = pd.read_pickle('/content/drive/My Drive/BT4222 Group/workspace/news_train_df.p')"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/BT4222 Group/workspace/news_train_df.p'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 173\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/BT4222 Group/workspace/news_train_df.p'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 177\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/BT4222 Group/workspace/news_train_df.p'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mread_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/BT4222 Group/workspace/news_train_df.p'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 173\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=False))\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# compat pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/BT4222 Group/workspace/news_train_df.p'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-1e5af43d56e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nnews_train_df = pd.read_pickle('/content/drive/My Drive/BT4222 Group/workspace/news_train_df.p')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E722\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 return read_wrapper(\n\u001b[0;32m--> 177\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    144\u001b[0m         f, fh = _get_handle(path, 'rb',\n\u001b[1;32m    145\u001b[0m                             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                             is_text=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/BT4222 Group/workspace/news_train_df.p'"]}]},{"metadata":{"id":"2uqJcYv7BMZs","colab_type":"code","outputId":"49950729-aba9-437e-fd53-649d7bc82697","executionInfo":{"status":"ok","timestamp":1554444955824,"user_tz":-480,"elapsed":15138,"user":{"displayName":"Wei Han Chua","photoUrl":"","userId":"05534555087765695301"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["%%time\n","\n","market_train_df = pd.read_hdf('/content/drive/My Drive/BT4222 Group/workspace/market_train_df.h5')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["CPU times: user 5.12 s, sys: 1.44 s, total: 6.56 s\n","Wall time: 14.3 s\n"],"name":"stdout"}]},{"metadata":{"id":"0txY4eVaI90x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"d267dde0-4601-4db8-ee02-adf5dc29b7c3","executionInfo":{"status":"ok","timestamp":1554444974478,"user_tz":-480,"elapsed":647,"user":{"displayName":"Wei Han Chua","photoUrl":"","userId":"05534555087765695301"}}},"cell_type":"code","source":["market_train_df.columns.tolist()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['time',\n"," 'assetCode',\n"," 'assetName',\n"," 'volume',\n"," 'close',\n"," 'open',\n"," 'returnsClosePrevRaw1',\n"," 'returnsOpenPrevRaw1',\n"," 'returnsClosePrevMktres1',\n"," 'returnsOpenPrevMktres1',\n"," 'returnsClosePrevRaw10',\n"," 'returnsOpenPrevRaw10',\n"," 'returnsClosePrevMktres10',\n"," 'returnsOpenPrevMktres10',\n"," 'returnsOpenNextMktres10',\n"," 'universe']"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"XAw5XS3XBtJS","colab_type":"code","outputId":"8804a3aa-1037-449e-b6bd-0c7d22bdff1a","executionInfo":{"status":"ok","timestamp":1551967519525,"user_tz":-480,"elapsed":110213,"user":{"displayName":"Xiya Yang","photoUrl":"https://lh5.googleusercontent.com/-HjGg8ak5UCE/AAAAAAAAAAI/AAAAAAAAAB8/f4Xbh-gaCm4/s64/photo.jpg","userId":"11423776090843528023"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import lightgbm as lgb\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os\n","from itertools import chain\n","import time\n","import multiprocessing\n","import copy\n","import pickle\n","import datetime as dt\n","import h5py\n","import re\n","from subprocess import call\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.manifold import TSNE\n","from sklearn.neighbors import NearestNeighbors\n","import keras\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation\n","from keras.layers.recurrent import LSTM\n","from keras.models import load_model\n","from keras import backend as K\n","import gc\n","%matplotlib inline"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"9vYPKbwK3N29","colab_type":"code","colab":{}},"cell_type":"code","source":["news_columns_outlier = ['takeSequence', 'bodySize', 'sentenceCount', 'wordCount', 'sentimentWordCount', 'firstMentionSentence','noveltyCount12H',\\\n","                  'noveltyCount24H', 'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H', 'volumeCounts24H',\\\n","                  'volumeCounts3D','volumeCounts5D','volumeCounts7D']\n","\n","\n","def clip_outliers(data_frame, column_list, low=0.02, high=0.98):\n","    for column in column_list:\n","        this_column = data_frame[column]\n","        quant_df = this_column.quantile([low,high])\n","        low_limit = quant_df[low]\n","        high_limit = quant_df[high]\n","        data_frame[column] = data_frame[column].clip(lower=low_limit, upper=high_limit)\n","    return data_frame\n","\n","\n","def import_data(from_2009=False, sample=False, split_ratio=0.1):\n","    global market_train_df, news_train_df\n","    if sample:\n","        N = int(news_train_df.shape[0] * split_ratio)\n","        dt_end = news_train_df['time'].iloc[N]\n","        market_train_df = market_train_df[market_train_df['time'] <= dt_end]\n","        news_train_df = news_train_df[news_train_df['time'] <= dt_end]\n","        \n","    return (market_train_df, news_train_df)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IP0crflE4MjV","colab_type":"code","colab":{}},"cell_type":"code","source":["def apply_func(f):\n","    '''Apply the given function on the data and close the data'''\n","    file = 'df_roll.h5'\n","    data = h5py.File(file, 'r+')\n","    results = f(data)\n","    data.close()\n","    return results\n","\n","def get_keys():\n","    def f(data):\n","        return list(sorted(list(data['data'].keys())))\n","    return apply_func(f)\n","\n","def get_files(w):\n","    res = []\n","    for f in os.listdir():\n","        if re.search('^df_%s_\\d\\.h5$' % w, f):\n","            res.append(f)\n","    return res\n","\n","def rm_key(v):\n","    def helper(data):\n","        del data['data'][v]\n","    apply_func(helper)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SYUmC69r4V3M","colab_type":"code","colab":{}},"cell_type":"code","source":["# factorize columns\n","\n","def reduce_news(news_train_df):\n","#     news_train_df.drop(['provider','subjects','audiences','sourceTimestamp','firstCreated','sourceId','headline'],axis=1,inplace=True)\n","#     news_train_df.drop(['provider','subjects','audiences','sourceTimestamp','firstCreated','sourceId'],axis=1,inplace=True)\n","    news_train_df.drop(['subjects','audiences','sourceTimestamp','firstCreated'],axis=1,inplace=True)\n","    \n","#     for column in ['sourceId', 'provider', 'headlineTag']:\n","#         news_train_df[column], uniques = pd.factorize(news_train_df[column])\n","#         del uniques\n","    \n","    # convert data types\n","    news_train_df['relevance']=news_train_df['relevance'].astype('float32')\n","    news_train_df['sentimentNegative']=news_train_df['sentimentNegative'].astype('float32')\n","    news_train_df['sentimentNeutral']=news_train_df['sentimentNeutral'].astype('float32')\n","    news_train_df['sentimentPositive']=news_train_df['sentimentPositive'].astype('float32')\n","    \n","    for c in news_train_df:\n","        if news_train_df[c].dtype == bool:\n","            news_train_df[c] = news_train_df[c].astype('int8')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7S_rI-_d4ZwG","colab_type":"code","colab":{}},"cell_type":"code","source":["def fill_subjects(cat_subjects_dict, news_train_df, is_test=False):\n","    if is_test:\n","        enum = enumerate(news_train_df['subjects'].cat.categories[news_train_df['subjects'].cat.codes].str.findall(f\"'([\\w\\./]+)'\"))\n","    else:\n","        enum = enumerate(news_train_df['subjects'].str.findall(f\"'([\\w\\./]+)'\"))\n","#     for i,ls_subjects in enumerate(news_train_df['subjects'].cat.categories[news_train_df['subjects'].cat.codes].str.findall(f\"'([\\w\\./]+)'\")):\n","#     for i,ls_subjects in enumerate(news_train_df['subjects'].str.findall(f\"'([\\w\\./]+)'\")):\n","    for i,ls_subjects in enum:\n","#         if i == 100000:\n","#             print('reached 100k')\n","        st_subjects = set(ls_subjects)\n","        for s in cat_subjects_dict:\n","            cat_subjects_dict[s][i] = int(s in st_subjects)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iwnhseIJ4bnX","colab_type":"code","colab":{}},"cell_type":"code","source":["news_cols_agg = {\n","    'urgency': ['min', 'count'],\n","    'takeSequence': ['min', 'max'],\n","    'bodySize': ['mean'],\n","    'wordCount': ['mean'],\n","    'sentenceCount': ['mean'],\n","    'companyCount': ['mean'],\n","    'marketCommentary': ['mean'],\n","    'relevance': ['mean'],\n","    'sentimentNegative': ['mean'],\n","    'sentimentNeutral': ['mean'],\n","    'sentimentPositive': ['mean'],\n","    'sentimentWordCount': ['mean'],\n","    'noveltyCount12H': ['mean'],\n","    'noveltyCount24H': ['mean'],\n","    'noveltyCount3D': ['mean'],\n","    'noveltyCount5D': ['mean'],\n","    'noveltyCount7D': ['mean'],\n","    'volumeCounts12H': ['mean'],\n","    'volumeCounts24H': ['mean'],\n","    'volumeCounts3D': ['mean'],\n","    'volumeCounts5D': ['mean'],\n","    'volumeCounts7D': ['mean']\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZbPBoeCE4hfe","colab_type":"code","colab":{}},"cell_type":"code","source":["def convert_float_cols(df):\n","    for c in df:\n","        if df[c].dtype=='float16' or df[c].dtype=='float64': # for lgb\n","            df[c] = df[c].astype('float32')\n","\n","            \n","def convert_object_to_float(data):\n","    for column in data:\n","        if data[column].dtype == 'O':\n","            if column in ['time', 'assetCode', 'assetName']:\n","                continue\n","            data[column] = data[column].astype('float32')\n","\n","\n","def exp_news_train_df(extra_columns, market_train_df=None, news_train_df=None):\n","    ls_keep = ['headline']\n","    \n","    is_test = True\n","    if news_train_df is None:\n","        is_test = False\n","        (market_train_df, news_train_df) = import_data()\n","        del market_train_df\n","    \n","    reduce_news(news_train_df)\n","    \n","    ls_extra = []\n","    for c in extra_columns:\n","        ls_extra.append(c)\n","        news_train_df[c] = extra_columns[c]\n","    \n","    # Split date into before and after 22h (the time used in train data)\n","    # E.g: 2007-03-07 23:26:39+00:00 -> 2007-03-08 00:00:00+00:00 (next day)\n","    #      2009-02-25 21:00:50+00:00 -> 2009-02-25 00:00:00+00:00 (current day)\n","    news_train_df['time'] = (news_train_df['time'] - np.timedelta64(22,'h')).dt.ceil('1D')\n","    \n","    if not is_test:\n","        news_train_df = news_train_df.set_index('time')\n","        ls_breakpoints = [None] + pd.date_range(news_train_df.index[0], news_train_df.index[-1], freq='Y').tolist() + [None]\n","\n","        for f in get_files('roll'):\n","            call(['rm', f])\n","        for f in get_files('news'):\n","            call(['rm', f])\n","        for i in range(len(ls_breakpoints)-1):\n","            print('proc batch %d' % (i+1))\n","            dt1, dt2 = ls_breakpoints[i], ls_breakpoints[i+1]\n","            print('handling until %s' % dt2)\n","            dt2 = dt2-dt.timedelta(days=1) if dt2 else dt2 # handle dt2 if not None\n","            df_cur = news_train_df[dt1:dt2].reset_index()\n","            if df_cur.empty:\n","                continue\n","            df_cur['assetCodes'] = df_cur['assetCodes'].cat.categories[df_cur['assetCodes'].cat.codes].str.findall(f\"'([\\w\\./]+)'\")\n","            assetCodes_expanded = list(chain(*df_cur['assetCodes']))\n","            assetCodes_index = df_cur.index.repeat( df_cur['assetCodes'].apply(len) )\n","            df_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n","            news_cols = ['time', 'assetCodes'] + list(news_cols_agg.keys()) + ls_extra + ls_keep\n","            df_cur_exp = pd.merge(df_assetCodes, df_cur[news_cols], left_on='level_0', right_index=True, suffixes=(['','_old']))\n","            df_cur_exp.to_hdf('df_roll_%s.h5' % i, 'data')\n","    else:\n","        # test\n","        news_train_df['assetCodes'] = news_train_df['assetCodes'].cat.categories[news_train_df['assetCodes'].cat.codes].str.findall(f\"'([\\w\\./]+)'\")\n","        assetCodes_expanded = list(chain(*news_train_df['assetCodes']))\n","        assetCodes_index = news_train_df.index.repeat( news_train_df['assetCodes'].apply(len) )\n","        df_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n","        news_cols = ['time', 'assetCodes'] + sorted(news_cols_agg.keys()) + ls_extra + ls_keep\n","        news_train_df_expanded = pd.merge(df_assetCodes, news_train_df[news_cols], left_on='level_0', right_index=True, suffixes=(['','_old']))\n","        return news_train_df_expanded\n","\n","\n","def agg_news_train_df(args):\n","    # TODO: move logic for single agg out\n","    (news_train_df_expanded, extra_columns, extra_columns_agg) = args\n","    # Aggregate numerical news features\n","    news_cols_agg_local = copy.deepcopy(news_cols_agg)\n","    news_cols_agg_local.update(extra_columns_agg)\n","\n","    if news_train_df_expanded is not None:\n","        # test\n","        df_headlines = pd.DataFrame(\n","            news_train_df_expanded.reset_index().groupby(['time', 'assetCode'])['headline'].agg(lambda x:'. '.join(x))\n","        ).reset_index()\n","        \n","        news_train_df_aggregated = news_train_df_expanded.groupby(['time', 'assetCode']).agg(news_cols_agg_local)\n","        news_train_df_aggregated.columns = ['_'.join(col).strip() for col in news_train_df_aggregated.columns.values]\n","        del news_train_df_expanded\n","        convert_float_cols(news_train_df_aggregated)\n","        return news_train_df_aggregated, df_headlines\n","        \n","    ls_h5_files = get_files('roll')\n","    ls_extra = list(extra_columns.keys())\n","\n","    for h5f in ls_h5_files:\n","        h5k = re.search('\\d', h5f).group(0)\n","        print('handling batch %s' % h5k)\n","        df_cur = pd.read_hdf(h5f, 'data')\n","        pd.DataFrame(\n","            df_cur.reset_index().groupby(['time', 'assetCode'])['headline'].agg(lambda x:'. '.join(x))\n","        ).reset_index().to_hdf('df_news_%s.h5' % h5k, 'data')\n","        df_cur = df_cur.reset_index().groupby(['time', 'assetCode']).agg(news_cols_agg_local)\n","        df_cur.columns = ['_'.join(col).strip() for col in df_cur.columns.values]\n","        convert_float_cols(df_cur)\n","        call(['rm', h5f])\n","        df_cur.to_hdf(h5f, 'data')\n","\n","\n","def get_market_data(market_train_df=None, news_train_df=None, skipOR=False, get_last_only=False, last_rows=None):\n","    if market_train_df is None and news_train_df is None:\n","        (market_train_df, news_train_df) = import_data()\n","        del news_train_df\n","        gc.collect()\n","\n","    market_train_df['time'] = market_train_df['time'].dt.floor('1D')\n","    \n","    market_train_df['open_close'] = market_train_df['close'] / market_train_df['open'] - 1\n","    market_train_df['oc_average'] = (market_train_df['close'] + market_train_df['open']) / 2\n","    market_train_df['turnover'] = market_train_df['close'] * market_train_df['volume']\n","\n","    relative_feature_names = [\n","        'open_close',\n","        'turnover',\n","        'volume',\n","        'returnsOpenPrevMktres1',\n","        'returnsOpenPrevMktres10',\n","    ]\n","    \n","    print('generating relative features..')\n","    if get_last_only:\n","        if market_train_df.shape[0] >= 2:\n","            dt_last = market_train_df['time'].iloc[-1]\n","            market_train_df = market_train_df.set_index('time').loc[dt_last, :]\n","\n","            df_relative = market_train_df[relative_feature_names].rename(columns = {\n","                feature_name: feature_name + '_relative' for feature_name in relative_feature_names\n","            })\n","            df_relative = (df_relative - df_relative.mean(axis=0)) / df_relative.std(axis=0)\n","            market_train_df = pd.concat([market_train_df, df_relative], axis=1)\n","            \n","    else:\n","        market_grouped = market_train_df.set_index('time').groupby('time')\n","        original_index = market_train_df.set_index('time').index\n","        del market_train_df\n","        market_train_df = None\n","\n","        count = 0\n","        for idx, df_time in market_grouped:\n","            count += 1\n","            if count % 1000 == 0:\n","                print('%dth day..' % count)\n","            if df_time.shape[0] < 2:\n","                continue\n","            df_relative = df_time[relative_feature_names].rename(columns = {\n","                feature_name: feature_name + '_relative' for feature_name in relative_feature_names\n","            })\n","            df_relative = (df_relative - df_relative.mean(axis=0)) / df_relative.std(axis=0)\n","            df_with_relative = pd.concat([df_time, df_relative], axis=1)\n","\n","            if market_train_df is None:\n","                market_train_df = pd.DataFrame(\n","                    index = original_index,\n","                    columns = df_with_relative.columns\n","                )\n","            market_train_df.loc[idx, :] = df_with_relative.values\n","        del market_grouped\n","        gc.collect()\n","    \n","    # reset index\n","    market_train_df = market_train_df.reset_index()\n","    \n","    print('[relative] Converting object columns to float..')\n","    convert_object_to_float(market_train_df)\n","    print('Finished converting..')\n","    \n","    print('finished creating features..')\n","    \n","    if 'returnsOpenNextMktres10' in market_train_df.columns:\n","        market_train_df['returnsOpenNextMktres10'] = market_train_df['returnsOpenNextMktres10'].astype('float32')\n","    if 'universe' in market_train_df.columns:\n","        market_train_df['universe'] = market_train_df['universe'].astype('int8')\n","\n","    return market_train_df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0TrsQZqc4lH2","colab_type":"code","outputId":"7e1efabd-2ccb-4f2e-de98-02cfd884bc2a","executionInfo":{"status":"error","timestamp":1551967667039,"user_tz":-480,"elapsed":256789,"user":{"displayName":"Xiya Yang","photoUrl":"https://lh5.googleusercontent.com/-HjGg8ak5UCE/AAAAAAAAAAI/AAAAAAAAAB8/f4Xbh-gaCm4/s64/photo.jpg","userId":"11423776090843528023"}},"colab":{"base_uri":"https://localhost:8080/","height":1554}},"cell_type":"code","source":["%%time\n","\n","def save_market_data(_):\n","    market_data = get_market_data(skipOR=False)\n","    market_data = market_data[~market_data['assetCode'].isin(['PGN.N','EBRYY.OB'])]\n","    if 'df_market_data.h5' in os.listdir():\n","        !rm df_market_data.h5\n","    market_data.to_hdf('df_market_data.h5', 'data')\n","\n","with multiprocessing.Pool(1) as pool:\n","    pool.map(save_market_data, [None])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["generating relative features..\n","1000th day..\n","2000th day..\n","[relative] Converting object columns to float..\n","Finished converting..\n","finished creating features..\n"],"name":"stdout"},{"output_type":"stream","text":["Process ForkPoolWorker-1:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n","    return list(map(*args))\n","  File \"<timed exec>\", line 6, in save_market_data\n","  File \"/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\", line 67, in system\n","    output = _system_commands._system_compat(self, *args, **kwargs)  # pylint:disable=protected-access\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-79c3058f32fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\ndef save_market_data(_):\\n    market_data = get_market_data(skipOR=False)\\n    market_data = market_data[~market_data['assetCode'].isin(['PGN.N','EBRYY.OB'])]\\n    if 'df_market_data.h5' in os.listdir():\\n        !rm df_market_data.h5\\n    market_data.to_hdf('df_market_data.h5', 'data')\\n\\nwith multiprocessing.Pool(1) as pool:\\n    pool.map(save_market_data, [None])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         '''\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"hw2vJYs76TqB","colab_type":"code","outputId":"cc27bdeb-983f-4014-f1cf-d973c9861c6b","executionInfo":{"status":"ok","timestamp":1551969662171,"user_tz":-480,"elapsed":81620,"user":{"displayName":"Xiya Yang","photoUrl":"https://lh5.googleusercontent.com/-HjGg8ak5UCE/AAAAAAAAAAI/AAAAAAAAAB8/f4Xbh-gaCm4/s64/photo.jpg","userId":"11423776090843528023"}},"colab":{"base_uri":"https://localhost:8080/","height":476}},"cell_type":"code","source":["%%time\n","\n","with multiprocessing.Pool(1) as pool:\n","    pool.map(exp_news_train_df, [{}])[0]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["proc batch 1\n","handling until 2007-12-31 00:00:00+00:00\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:2378: PerformanceWarning: \n","your performance may suffer as PyTables will pickle object types that it cannot\n","map directly to c-types [inferred_type->mixed,key->block6_values] [items->['assetCode', 'assetCodes', 'headline']]\n","\n","  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"],"name":"stderr"},{"output_type":"stream","text":["proc batch 2\n","handling until 2008-12-31 00:00:00+00:00\n","proc batch 3\n","handling until 2009-12-31 00:00:00+00:00\n","proc batch 4\n","handling until 2010-12-31 00:00:00+00:00\n","proc batch 5\n","handling until 2011-12-31 00:00:00+00:00\n","proc batch 6\n","handling until 2012-12-31 00:00:00+00:00\n","proc batch 7\n","handling until 2013-12-31 00:00:00+00:00\n","proc batch 8\n","handling until 2014-12-31 00:00:00+00:00\n","proc batch 9\n","handling until 2015-12-31 00:00:00+00:00\n","proc batch 10\n","handling until None\n","CPU times: user 93.6 ms, sys: 105 ms, total: 198 ms\n","Wall time: 1min 20s\n"],"name":"stdout"}]},{"metadata":{"id":"-H0RY3D3k84h","colab_type":"code","outputId":"37a34c83-a05d-4a01-e4f6-f0e5de5b4cee","executionInfo":{"status":"ok","timestamp":1551969887642,"user_tz":-480,"elapsed":306542,"user":{"displayName":"Xiya Yang","photoUrl":"https://lh5.googleusercontent.com/-HjGg8ak5UCE/AAAAAAAAAAI/AAAAAAAAAB8/f4Xbh-gaCm4/s64/photo.jpg","userId":"11423776090843528023"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"cell_type":"code","source":["%%time\n","\n","with multiprocessing.Pool(1) as pool:\n","    pool.map(agg_news_train_df, [(None, {}, {})])[0]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["handling batch 3\n","handling batch 6\n","handling batch 1\n","handling batch 7\n","handling batch 4\n","handling batch 9\n","handling batch 5\n","handling batch 0\n","handling batch 2\n","handling batch 8\n","CPU times: user 191 ms, sys: 151 ms, total: 342 ms\n","Wall time: 3min 45s\n"],"name":"stdout"}]},{"metadata":{"id":"IWNGZmrMmQ1s","colab_type":"code","colab":{}},"cell_type":"code","source":["def label_encode(series, min_count, encoder_dict):\n","    vc = series.value_counts()\n","    max_value = max(list(encoder_dict.values)) if len(encoder_dict) else 0\n","    for i, c in enumerate(vc.index[vc >= min_count]):\n","        if c in encoder_dict:\n","            continue\n","        encoder_dict[c] = max_value + i\n","    return encoder_dict\n","\n","\n","def make_test(market_train_df, news_train_df_aggregated, df_headlines):\n","    df_xtr = market_train_df.join(news_train_df_aggregated, on=['time', 'assetCode']) \n","    df_xtr = df_xtr.join(df_headlines.set_index(['time', 'assetCode']), on=['time', 'assetCode'])\n","    \n","    df_xtr['dayofweek'], df_xtr['month'] = df_xtr.time.dt.dayofweek, df_xtr.time.dt.month\n","#     ls_todrop = ['assetName']\n","    ls_todrop = []\n","    df_xtr.drop(ls_todrop, axis=1, inplace=True)\n","    return df_xtr\n","\n","\n","def build_train(_):\n","    # for train\n","    if 'df_roll.h5' in os.listdir():\n","        !rm df_roll.h5\n","    if 'df_market_data.h5' not in os.listdir():\n","        raise Exception('Create market data first')\n","    market_train_df = pd.read_hdf('df_market_data.h5', 'data')\n","    market_train_df['time'] = market_train_df['time'].dt.tz_localize(None)\n","    market_train_df = market_train_df.set_index('time')\n","    ls_xtr = []\n","    encoder_dict = {}\n","    for h5f in sorted(get_files('roll')):\n","        h5k = re.search('\\d', h5f).group(0)\n","        print('proc batch %s' % h5k)\n","        df_agg = pd.read_hdf(h5f, 'data')\n","        df_news = pd.read_hdf('df_news_%s.h5' % h5k, 'data')\n","        df_news['time'] = df_news['time'].dt.tz_localize(None)\n","        dt1, dt2 = df_agg.index[0][0], df_agg.index[-1][0]\n","        df_xtr = market_train_df[dt1:dt2].reset_index().join(df_agg, on=['time', 'assetCode'])\n","        df_xtr = df_xtr.join(df_news.set_index(['time', 'assetCode']), on=['time', 'assetCode'])\n","        \n","        # keep assetName\n","#         df_xtr.drop('assetName', axis=1, inplace=True)\n","        \n","        df_xtr['dayofweek'], df_xtr['month'] = df_xtr.time.dt.dayofweek, df_xtr.time.dt.month\n","        ls_xtr.append(df_xtr)\n","        call(['rm', h5f])\n","        call(['rm', 'df_news_%s.h5' % h5k])\n","    df_xtr = pd.concat(ls_xtr)\n","    \n","    # create headline features\n","    # create headline features later to avoid leakage\n","#     headline_features = transform_headlines(df_xtr['headline'])\n","#     df_xtr = df_xtr.drop(columns=['headline'])\n","#     for column in headline_features:\n","#         df_xtr[column] = headline_features[column]\n","\n","    le_assetCode = label_encode(df_xtr['assetCode'], 10, encoder_dict)\n","#     df_xtr.to_hdf('df_roll.h5', 'data')\n","#     df_xtr.to_pickle('df_roll.p')\n","    return le_assetCode, df_xtr\n","\n","#     return le_assetCode, le_assetName"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GPs7YOUQlW1V","colab_type":"code","outputId":"1c3aedf8-76d5-4da0-e6c7-8b534ab332be","executionInfo":{"status":"ok","timestamp":1551970169744,"user_tz":-480,"elapsed":68678,"user":{"displayName":"Xiya Yang","photoUrl":"https://lh5.googleusercontent.com/-HjGg8ak5UCE/AAAAAAAAAAI/AAAAAAAAAB8/f4Xbh-gaCm4/s64/photo.jpg","userId":"11423776090843528023"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"cell_type":"code","source":["%%time\n","\n","with multiprocessing.Pool(1) as pool:\n","#     le_assetCode, le_assetName = pool.map(build_train, [None])[0]\n","    le_assetCode, df_xtr = pool.map(build_train, [None])[0]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["proc batch 0\n","proc batch 1\n","proc batch 2\n","proc batch 3\n","proc batch 4\n","proc batch 5\n","proc batch 6\n","proc batch 7\n","proc batch 8\n","proc batch 9\n","CPU times: user 2.17 s, sys: 3.21 s, total: 5.38 s\n","Wall time: 1min 7s\n"],"name":"stdout"}]},{"metadata":{"id":"s1gQnWv-vuo9","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","df_xtr.to_pickle('/content/drive/My Drive/BT4222 Group/workspace/data/combined.p')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8KLVlk6Iv78R","colab_type":"text"},"cell_type":"markdown","source":["### Remark\n","* The following code blocks are related to model building instead of preprocessing"]},{"metadata":{"id":"1gkzZsrfmicW","colab_type":"code","colab":{}},"cell_type":"code","source":["def sigma_score(preds, valid_data):\n","    df_time = valid_data.params['extra_time']\n","    labels = valid_data.get_label()\n","    \n","    assert len(labels) == len(df_time)\n","    \n","    x_t = preds * labels\n","\n","    x_t_sum = x_t.groupby(df_time).sum()\n","    score = x_t_sum.mean() / x_t_sum.std()\n","    return 'sigma_score', score, True\n","\n","\n","def sigma_score_plain(preds, labels, ds_time):\n","    x_t = preds * labels\n","    x_t_sum = x_t.groupby(ds_time.values).sum()\n","    score = x_t_sum.mean() / x_t_sum.std()\n","    return score"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G8H9BlEymoiM","colab_type":"code","colab":{}},"cell_type":"code","source":["lgb_params = dict(\n","    objective = 'regression_l1',\n","    learning_rate = 0.1,\n","    num_leaves = 12,\n","    max_depth = 50,\n","#     min_data_in_leaf = 1000,\n","#     min_sum_hessian_in_leaf = 10,\n","    bagging_fraction = 0.75,\n","    bagging_freq = 2,\n","    feature_fraction = 0.5,\n","    lambda_l1 = 0.0,\n","    lambda_l2 = .1,\n","    metric = 'l2', # bbb\n","    seed = 42\n",")\n","\n","# potential area for improvement\n","\n","\n","class BaseModel():\n","    def __init__(self):\n","        self.model = None\n","        self.xtr = None\n","        self.ytr = None\n","        self.xval = None\n","        self.yval = None\n","        self.lgb_params = lgb_params\n","        self.learning_rate_decay_fn = learning_rate_power\n","        \n","    \n","    \n","    def fit(self, xtr, ytr):\n","        raise Exception('Not implemented. Override this method.')\n","    \n","    \n","    def predict(self, xval):\n","        raise Exception('Not implemented. Override this method.')\n","        \n","\n","\n","class LGBBasicModel(BaseModel):\n","    def __init__(self, ban_words=None):\n","        self.categorical_cols = ['dayofweek', 'month']\n","        self.lgb_params = lgb_params\n","        self.remove_list = ['time', 'universe', 'returnsOpenNextMktres10', 'assetCode', 'assetName', 'headline']\n","        self.ban_words = ban_words\n","        \n","\n","    def fit_eval(self, xtr, ytr, xval, yval, num_rounds=None):\n","        self.fit_full(xtr, ytr, num_rounds)\n","        return self.predict(xval)\n","        \n","        \n","    def _filter_regex(self, data):\n","        return data\n","    \n","    \n","    def predict(self, xval):\n","        ls_to_drop = []\n","            \n","        for c in self.remove_list:\n","            if c in xval.columns:\n","                ls_to_drop.append(c)\n","        xval = xval.drop(columns=ls_to_drop)\n","            \n","        xval = self._filter_regex(xval)\n","        \n","        xval = xval[self.train_cols]\n","        return self.model.predict(xval)\n","    \n","    \n","    def fit(self, xtr, ytr):\n","        if self.ban_words is not None:\n","            drop_list = []\n","            for col in xtr.columns:\n","                for ban_word in self.ban_words:\n","                    if ban_word in col:\n","                        drop_list.append(col)\n","                        break\n","            xtr = xtr.drop(columns=drop_list)\n","            \n","        # actual training and validation sets\n","        xtr_, xval_, ytr_, yval_ = train_test_split(xtr, ytr, test_size=0.2, shuffle=False)\n","        \n","        valid_params = {\n","            'extra_time': xval_['time'].factorize()[0]\n","        }\n","        \n","        ls_to_drop = []\n","        for col in self.remove_list:\n","            if col in xtr_.columns:\n","                ls_to_drop.append(col)\n","        \n","        xtr_ = xtr_.drop(columns=ls_to_drop)\n","        xval_ = xval_.drop(columns=ls_to_drop)\n","        \n","        xtr_ = self._filter_regex(xtr_)\n","        xval_ = self._filter_regex(xval_)\n","        \n","        train_cols = xtr_.columns.tolist()\n","        \n","        # Note: y data is expected to be a pandas Series, as we will use its group_by function in `sigma_score`\n","        dtrain = lgb.Dataset(xtr_.values, ytr_, feature_name=train_cols, categorical_feature=self.categorical_cols, free_raw_data=False)\n","        dvalid = lgb.Dataset(xval_.values, yval_, feature_name=train_cols, categorical_feature=self.categorical_cols, free_raw_data=False)\n","        dvalid.params = valid_params\n","        evals_result = {}\n","        m = lgb.train(lgb_params, dtrain, num_boost_round=1000, valid_sets=(dvalid,), valid_names=('valid',), verbose_eval=25,\n","                      early_stopping_rounds=100, evals_result=evals_result)\n","        self.train_cols = train_cols\n","        self.model = m\n","        self.evals_result = evals_result\n","    \n","    \n","    def fit_full(self, xtr, ytr, num_rounds=None):\n","        if self.ban_words is not None:\n","            drop_list = []\n","            for col in xtr.columns:\n","                for ban_word in self.ban_words:\n","                    if ban_word in col:\n","                        drop_list.append(col)\n","                        break\n","            xtr = xtr.drop(columns=drop_list)\n","        \n","        if num_rounds is None:\n","            df_result = pd.DataFrame(self.evals_result['valid'])\n","            num_rounds = df_result['l2'].argmax()+1\n","        \n","        ls_to_drop = []\n","        for col in self.remove_list:\n","            if col in xtr.columns:\n","                ls_to_drop.append(col)\n","        \n","        xtr = xtr.drop(columns=ls_to_drop)\n","        xtr = self._filter_regex(xtr)\n","        \n","        train_cols = xtr.columns.tolist()\n","        dtrain = lgb.Dataset(xtr.values, ytr, feature_name=train_cols, categorical_feature=self.categorical_cols, free_raw_data=False)\n","        \n","        m = lgb.train(self.lgb_params, dtrain, num_boost_round=num_rounds)\n","        self.train_cols = train_cols\n","        self.model = m"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cTr0_oXisqGD","colab_type":"code","colab":{}},"cell_type":"code","source":["%%time\n","\n","def get_stack_data(models):\n","#     df_xtr = pd.read_hdf('df_roll.h5', 'data')\n","#     df_xtr = pd.read_pickle('df_roll.p')\n","#     df_xtr = df_xtr.drop(columns='headline')\n","    \n","    global df_xtr\n","    \n","    arr_dates = df_xtr['time'].unique()\n","    dt_start = arr_dates[-(arr_dates.shape[0] // 504) * 504]\n","    \n","    df_xtr = df_xtr[df_xtr['time'] >= dt_start]\n","    \n","    target = df_xtr['returnsOpenNextMktres10'].copy()\n","#     stack_data = stack_models(df_xtr, models)\n","    \n","    stack_data = df_xtr\n","    \n","    stack_data['sentimentPositive_outperform'] = stack_data['sentimentPositive_mean'] - stack_data['sentimentPositive_mean'].mean()\n","    stack_data['sentimentNegative_outperform'] = stack_data['sentimentNegative_mean'] - stack_data['sentimentNegative_mean'].mean()\n","#     stack_data['open_close_outperform'] = stack_data['open_close'] - stack_data['open_close'].mean()\n","#     stack_data['returnsOpenPrevMktres1_outperform'] = stack_data['returnsOpenPrevMktres1'] - stack_data['returnsOpenPrevMktres1'].mean()\n","#     stack_data['returnsOpenPrevMktres10_outperform'] = stack_data['returnsOpenPrevMktres10'] - stack_data['returnsOpenPrevMktres10'].mean()\n","\n","#     stack_data.to_hdf('stack_data.h5', 'data')\n","#     stack_data.to_pickle('stack_data.p')\n","#     return stack_data, target\n","    return stack_data\n","\n","with multiprocessing.Pool(1) as pool:\n","    df_stack = pool.map(get_stack_data, [None])[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"laupIRa4q-6e","colab_type":"code","colab":{}},"cell_type":"code","source":["def cv_stack(X, model, k=5, seq=True, cv_type='model'):\n","    if seq:\n","        k += 1\n","        breakpoints = [int(float(X.shape[0])*i/float(k)) for i in range(1, k)] + [X.shape[0]]\n","    else:\n","        breakpoints = [int(float(X.shape[0])*i/float(k)) for i in range(k)] + [X.shape[0]]\n","    X = X.set_index('time')\n","    y = X['returnsOpenNextMktres10']\n","    X = X.drop(columns=['returnsOpenNextMktres10'])\n","    res = []\n","    \n","    for i in range(len(breakpoints)-1):\n","        # skip to last round (remove)\n","        if i+1 < len(breakpoints)-1:\n","            continue\n","            \n","        p1, p2 = breakpoints[i], breakpoints[i+1]\n","        dt1, dt2 = X.index[p1], X.index[p2] if p2 < X.shape[0] else None\n","        \n","        dt1, dt2 = pd.to_datetime(dt1), pd.to_datetime(dt2)\n","        X_train = X[:dt1 - dt.timedelta(days=1)].reset_index()\n","        y_train = y[:dt1 - dt.timedelta(days=1)]\n","        X_test = X[dt1:dt2].reset_index()\n","        y_test = y[dt1:dt2]\n","        ds_time = X[dt1:dt2].index\n","        \n","        \n","        print('Fold %d (%s to %s)' % (i+1, dt1, dt2))\n","        if seq:\n","            if cv_type == 'model':\n","                model.fit_full(X_train, y_train, num_rounds=200)\n","                preds = model.predict(X_test)\n","            elif cv_type == 'average':\n","                preds = X_test.mean(axis=1)\n","            elif cv_type == 'majority':\n","                preds = []\n","                for row in X_test.values:\n","                    if (row > 0).sum() > X.shape[1] / 2:\n","                        preds.append(row[row>0].mean())\n","                    else:\n","                        preds.append(row[row<=0].mean())\n","            else:\n","                raise Exception('Unsupported')\n","            score = sigma_score_plain(np.array(preds), y_test, ds_time)\n","            res.append(score)\n","        else:\n","            raise Exception('Not supported')\n","            arr_flags = (np.arange(X.shape[0]) < dt1) | (np.arange(X.shape[0]) >= dt2)\n","            res.append(fit_val\n","                       (X[arr_flags], y[arr_flags], X.iloc[dt1:dt2], y.iloc[dt1:dt2]))\n","    return res"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WEb6eckNsQQM","colab_type":"code","outputId":"829965f0-9ad5-4e5a-dc57-b71818cfaef0","executionInfo":{"status":"error","timestamp":1551974247228,"user_tz":-480,"elapsed":919,"user":{"displayName":"Xiya Yang","photoUrl":"https://lh5.googleusercontent.com/-HjGg8ak5UCE/AAAAAAAAAAI/AAAAAAAAAB8/f4Xbh-gaCm4/s64/photo.jpg","userId":"11423776090843528023"}},"colab":{"base_uri":"https://localhost:8080/","height":589}},"cell_type":"code","source":["%%time\n","\n","cv_results = cv_stack(df_stack, LGBBasicModel(), cv_type='model')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-96e97bc17052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\ncv_results = cv_stack(df_stack, LGBBasicModel(), cv_type='model')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df_stack' is not defined"]}]},{"metadata":{"id":"GevLPKxl3092","colab_type":"code","outputId":"ace6757f-6d77-4c00-a60f-b6061eeeeb90","executionInfo":{"status":"error","timestamp":1551974227888,"user_tz":-480,"elapsed":984,"user":{"displayName":"Xiya Yang","photoUrl":"https://lh5.googleusercontent.com/-HjGg8ak5UCE/AAAAAAAAAAI/AAAAAAAAAB8/f4Xbh-gaCm4/s64/photo.jpg","userId":"11423776090843528023"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"cell_type":"code","source":["cv_results"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-650a0d7c2c5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'cv_results' is not defined"]}]}]}