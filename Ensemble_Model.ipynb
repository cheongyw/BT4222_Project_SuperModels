{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "IynNYayAaa9A",
        "oo1x2aRs1jGh"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "D6qOq0CPml_G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM Model"
      ]
    },
    {
      "metadata": {
        "id": "aqswqyzCBl11",
        "colab_type": "code",
        "outputId": "802e2d66-d3b4-4a65-83d5-bc17d36803f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "cell_type": "code",
      "source": [
        "# restart kernel after running this cell\n",
        "!pip install pandas --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 10.1MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.2)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.23.4\n",
            "    Uninstalling pandas-0.23.4:\n",
            "      Successfully uninstalled pandas-0.23.4\n",
            "Successfully installed pandas-0.24.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fIFW9iPEA8u3",
        "colab_type": "code",
        "outputId": "7d1f9be6-ae7e-4aab-f7ce-45cba3c7ae17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from itertools import chain\n",
        "import time\n",
        "import multiprocessing\n",
        "import copy\n",
        "import pickle\n",
        "import datetime as dt\n",
        "import h5py\n",
        "import re\n",
        "from subprocess import call\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import load_model\n",
        "from keras import Model\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "import gc\n",
        "from keras.layers import Input, LSTM, Bidirectional, Dense, Embedding\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aRHMnKEyvSzb",
        "colab_type": "code",
        "outputId": "cbf2f03e-5ac1-4849-f414-01e453468200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "combined_data = pd.read_pickle('/content/drive/My Drive/BT4222 Group/workspace/data/combined.p')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.1 s, sys: 2.98 s, total: 5.08 s\n",
            "Wall time: 16.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cGGUY0Rbd-D8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "combined_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xkMQyDd3wdHV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "combined_data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D4anoNVSxxyK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "combined_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eO3Mnm8i8B8n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "combined_data['assetCode'].unique().shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFCeP_OhIftf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_list = [\n",
        "    'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n",
        "       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n",
        "       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n",
        "       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n",
        "       'open_close', 'oc_average', 'turnover',]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CauYmsJi8LQo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "second_level_features = ['open_close_relative', 'turnover_relative', 'volume_relative', 'returnsOpenPrevMktres1_relative', 'returnsOpenPrevMktres10_relative',]\n",
        "features_list += second_level_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pz6Tqh6pcE3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reshape_data(data, sequence_len=21, features_list=features_list[:-len(second_level_features)]):\n",
        "  data_list, lgbm_list, target_list, returns_list, date_list = [], [], [], [], []\n",
        "\n",
        "  for assetCode, asset_data in data.groupby('assetCode'):\n",
        "    # binarize the target variable\n",
        "    returns = asset_data['returnsOpenNextMktres10']\n",
        "    target = (asset_data['returnsOpenNextMktres10'] > 0).astype(int)\n",
        "    dates = asset_data.index\n",
        "    asset_data = asset_data[features_list]\n",
        "    \n",
        "    # fill missing values with mean\n",
        "    ini_array = asset_data.values\n",
        "    col_mean = np.nanmean(ini_array, axis = 0) \n",
        "    inds = np.where(np.isnan(ini_array)) \n",
        "    ini_array[inds] = np.take(col_mean, inds[1])\n",
        "    \n",
        "    # safety net\n",
        "    ini_array = ini_array[~(np.isnan(ini_array).sum(axis=1) > 0)]\n",
        "    \n",
        "    # reshape data for LSTM\n",
        "    reshaped_data = np.repeat(ini_array[:, np.newaxis, :], sequence_len, axis=1)\n",
        "    for i in range(reshaped_data.shape[1]):\n",
        "      reshaped_data[:, i, :] = np.roll(reshaped_data[:, i, :], i, axis=0)\n",
        "\n",
        "    # discard the top rows and reverse the order of the shifted sequence to reflect the correct order\n",
        "    reshaped_data = reshaped_data[sequence_len-1:, ::-1, :]\n",
        "    ini_array = ini_array[sequence_len-1:, :]\n",
        "    target = target.values[sequence_len-1:]\n",
        "    returns = returns.values[sequence_len-1:]\n",
        "    dates = dates[sequence_len-1:]\n",
        "\n",
        "    data_list.append(reshaped_data)\n",
        "    lgbm_list.append(ini_array)\n",
        "    target_list.append(target)\n",
        "    returns_list.append(returns)\n",
        "    date_list.append(dates)\n",
        "  \n",
        "  reshaped_data, lgbm_data, target, returns, dates = np.concatenate(data_list), np.concatenate(lgbm_list), np.concatenate(target_list), np.concatenate(returns_list), np.concatenate(date_list)\n",
        "  \n",
        "  return reshaped_data, lgbm_data, target, returns, dates\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E0OayXdd2mSK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lstm_params = {\n",
        "    'batch_size': 252,\n",
        "    'epochs': 2,\n",
        "  }\n",
        "\n",
        "def create_model(stateful=False, sequence_len=21, batch_size=lstm_params['batch_size']):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(32,\n",
        "              input_shape=(sequence_len, len(features_list)-len(second_level_features)),\n",
        "              batch_size=batch_size,\n",
        "              stateful=stateful,\n",
        "              kernel_initializer='glorot_normal',\n",
        "              bias_initializer='zeros'))\n",
        "    model.add(Dense(1,\n",
        "              activation='sigmoid',\n",
        "              kernel_initializer='glorot_normal',\n",
        "              bias_initializer='zeros'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5A0-LAy8znzp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "#Set model params\n",
        "params = {}\n",
        "params['learning_rate'] = 0.5            # 0.003 to 0.1 gives significant increase in sigma\n",
        "params['boosting_type'] = 'gbdt'\n",
        "params['objective'] = 'binary'\n",
        "params['metric'] = 'binary_logloss'\n",
        "params['sub_feature'] = 0.5\n",
        "params['num_leaves'] = 30                # 10 to 30 gives significant increase in sigma\n",
        "params['min_data'] = 20\n",
        "params['max_depth'] = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Uqm-hBpinRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_sigma(scaled_scores, test_returns, test_dates):\n",
        "  '''\n",
        "  scaled_scores: numpy array\n",
        "  test_returns: numpy array\n",
        "  test_dates: numpy array\n",
        "  '''\n",
        "\n",
        "  grouped_dict = pd.Series(scaled_scores).index.groupby(test_dates)\n",
        "\n",
        "  day_scores = []\n",
        "  for ts in grouped_dict:\n",
        "    grouped_index = grouped_dict[ts]\n",
        "    day_score = np.dot(test_returns[grouped_index], scaled_scores[grouped_index])\n",
        "    day_scores.append(day_score)\n",
        "\n",
        "  return np.mean(day_scores) / np.std(day_scores, ddof=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-GEzQbVGxw-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reshape_LSTM_stack(data, sequence_len=21):\n",
        "  # reshape data for LSTM\n",
        "  reshaped_data = np.repeat(data[:, np.newaxis, :], sequence_len, axis=1)\n",
        "  for i in range(reshaped_data.shape[1]):\n",
        "    reshaped_data[:, i, :] = np.roll(reshaped_data[:, i, :], i, axis=0)\n",
        "\n",
        "  # discard the top rows and reverse the order of the shifted sequence to reflect the correct order\n",
        "  reshaped_data = reshaped_data[sequence_len-1:, ::-1, :]\n",
        "\n",
        "  return reshaped_data\n",
        "\n",
        "def reshape_LSTM_y(data, sequence_len=21):\n",
        "  return data[sequence_len-1:]\n",
        "\n",
        "\n",
        "def create_stack_model(stateful=False, sequence_len=21, batch_size=lstm_params['batch_size']):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(32,\n",
        "              input_shape=(sequence_len, len(second_level_features)+2),  ## need to change second parameter\n",
        "              batch_size=batch_size,\n",
        "              stateful=stateful,\n",
        "              kernel_initializer='glorot_normal',\n",
        "              bias_initializer='zeros'))\n",
        "    model.add(Dense(1,\n",
        "              activation='sigmoid',\n",
        "              kernel_initializer='glorot_normal',\n",
        "              bias_initializer='zeros'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E6f__yPV2GEX",
        "colab_type": "code",
        "outputId": "40d74182-b78b-4cfc-b0ca-b0bb3d709732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16855
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# array of start dates from Jan 2011-Jan 2016\n",
        "# array of end dates from Dec 2011-Dec 2016\n",
        "start_dates = ['2011-01-01','2012-01-01','2013-01-01','2014-01-01','2015-01-01','2016-01-01']\n",
        "train_end_dates = ['2011-12-31','2012-12-31','2013-12-31','2014-12-31','2015-12-31']\n",
        "val_end_dates = ['2012-06-30','2013-06-30','2014-06-30','2015-06-30','2016-06-30']\n",
        "stack_start_dates = ['2012-07-01','2013-07-01','2014-07-01','2015-07-01','2016-07-01']\n",
        "stack_end_dates = ['2012-12-31','2013-12-31','2014-12-31','2015-12-31','2016-12-31']\n",
        "\n",
        "# store prediction scores\n",
        "sigma_score = np.empty(0,)\n",
        "lstm_sigma = np.empty(0,)\n",
        "lgbm_sigma = np.empty(0,)\n",
        "accuracy_score = np.empty(0,)\n",
        "confusion_matrix = np.empty(0,)\n",
        "\n",
        "for item in range (0,5): \n",
        "    \n",
        "  # period for base model\n",
        "  train_start, train_end = pd.to_datetime(start_dates[item]), pd.to_datetime(train_end_dates[item])\n",
        "  temp = combined_data.set_index('time')[train_start: train_end]\n",
        "\n",
        "  n = int(len(temp)/6)  #chunk row size\n",
        "               \n",
        "  # period for validation model and stack model                                       \n",
        "  val_start, val_end = pd.to_datetime(start_dates[item+1]), pd.to_datetime(val_end_dates[item])\n",
        "  validation_set = combined_data.set_index('time')[val_start: val_end]\n",
        "  stack_start, stack_end = pd.to_datetime(stack_start_dates[item]), pd.to_datetime(stack_end_dates[item])\n",
        "  stack_set = combined_data.set_index('time')[stack_start: stack_end]\n",
        "                                          \n",
        "  stack_train_features = np.empty(shape = (0,(2+len(second_level_features))))\n",
        "  stack_val_features = np.empty(shape = (0,(2+len(second_level_features)))) \n",
        "  stack_test_features = np.empty(shape = (0,(2+len(second_level_features))))   \n",
        "  stack_train_y = np.empty(shape = (0,)) \n",
        "  \n",
        "  for i in range(0,6):\n",
        "      \n",
        "    if i != 5:\n",
        "      ## get predictions as features for stack model \n",
        "      train_data = temp[0:n*(i+1)] \n",
        "      validation_data = validation_set  \n",
        "      test_data = temp[n*(i+1):n*(i+2)]\n",
        "                                          \n",
        "    else:\n",
        "      ## get new features for stack test\n",
        "      train_data = temp\n",
        "      validation_data = validation_set\n",
        "      test_data = stack_set\n",
        "\n",
        "    train_data[features_list] = scaler.fit_transform(train_data[features_list])\n",
        "    validation_data[features_list] = scaler.transform(validation_data[features_list])\n",
        "    test_data[features_list] = scaler.transform(test_data[features_list])\n",
        "\n",
        "    # sampling\n",
        "\n",
        "    stocks = train_data['assetCode'].unique()\n",
        "\n",
        "    # N = min(100, stocks.shape[0])\n",
        "    N = stocks.shape[0]\n",
        "\n",
        "    np.random.seed(1)\n",
        "    selected_stocks = set(np.random.choice(stocks, N))\n",
        "    train_data = train_data[train_data['assetCode'].map(lambda x: x in selected_stocks)]\n",
        "    validation_data = validation_data[validation_data['assetCode'].map(lambda x: x in selected_stocks)]\n",
        "    test_data = test_data[test_data['assetCode'].map(lambda x: x in selected_stocks)]\n",
        "\n",
        "    # reshape data                                         \n",
        "    x_train, lgbm_train, y_train, train_returns, train_dates = reshape_data(train_data)\n",
        "    x_val, lgbm_val, y_val, val_returns, val_dates = reshape_data(validation_data)\n",
        "    x_test, lgbm_test, y_test, test_returns, test_dates = reshape_data(test_data)\n",
        "\n",
        "    # tweak to match with batch_size\n",
        "    train_until = x_train.shape[0] - x_train.shape[0] % lstm_params['batch_size']\n",
        "    val_until = x_val.shape[0] - x_val.shape[0] % lstm_params['batch_size']\n",
        "    test_until = x_test.shape[0] - x_test.shape[0] % lstm_params['batch_size']\n",
        "\n",
        "    x_train = x_train[:train_until]\n",
        "    y_train = y_train[:train_until]\n",
        "    lgbm_train = lgbm_train[:train_until]\n",
        "    train_returns = train_returns[:train_until]\n",
        "    train_dates = train_dates[:train_until]\n",
        "    x_val = x_val[:val_until]\n",
        "    y_val = y_val[:val_until]\n",
        "    lgbm_val = lgbm_val[:val_until]\n",
        "    val_returns = val_returns[:val_until]\n",
        "    val_dates = val_dates[:val_until]\n",
        "    x_test = x_test[:test_until]\n",
        "    y_test = y_test[:test_until]\n",
        "    lgbm_test = lgbm_test[:test_until]\n",
        "    test_returns = test_returns[:test_until]\n",
        "    test_dates = test_dates[:test_until]\n",
        "\n",
        "    np.random.seed(1)\n",
        "    train_shuffle = np.random.permutation(range(x_train.shape[0]))\n",
        "    lgbm_train_shuffle = np.random.permutation(range(lgbm_train.shape[0]))\n",
        "    val_shuffle = np.random.permutation(range(x_val.shape[0]))\n",
        "    lgbm_val_shuffle = np.random.permutation(range(lgbm_val.shape[0]))\n",
        "    test_shuffle = np.random.permutation(range(x_test.shape[0]))\n",
        "    lgbm_test_shuffle = np.random.permutation(range(lgbm_test.shape[0]))\n",
        "    x_train, lgbm_train, y_train, train_returns, train_dates = x_train[train_shuffle], lgbm_train[lgbm_train_shuffle], y_train[train_shuffle], train_returns[train_shuffle], train_dates[train_shuffle]\n",
        "    x_val, lgbm_val, y_val, val_returns, val_dates = x_val[val_shuffle], lgbm_val[lgbm_val_shuffle], y_val[val_shuffle], val_returns[val_shuffle], val_dates[val_shuffle]\n",
        "    x_test, lgbm_test, y_test, test_returns, test_dates = x_test[test_shuffle], lgbm_test[lgbm_test_shuffle], y_test[test_shuffle], test_returns[test_shuffle], test_dates[test_shuffle]\n",
        "\n",
        "\n",
        "    lstm_model = create_model()\n",
        "\n",
        "    if second_level_features == []:\n",
        "      \n",
        "      # LGBM model\n",
        "      \n",
        "      d_train = lgb.Dataset(lgbm_train, label=y_train)\n",
        "\n",
        "      lgbmodel = lgb.train(params, d_train, 100)\n",
        "      \n",
        "      scaled_val_scores_lgbm = lgbmodel.predict(lgbm_val, batch_size=252).reshape(-1) * 2 - 1\n",
        "      scaled_scores_lgbm = lgbmodel.predict(lgbm_test, batch_size=252).reshape(-1) * 2 - 1\n",
        "      lgbm_sigma = np.append(lgbm_sigma, get_sigma(scaled_scores_lgbm, test_returns, test_dates))\n",
        "      \n",
        "      # LSTM model\n",
        "      \n",
        "      if i != 5:\n",
        "      \n",
        "        lstm_model.fit(x_train,\n",
        "                     y_train,\n",
        "                     batch_size=lstm_params['batch_size'],\n",
        "                     epochs= lstm_params['epochs'],\n",
        "                     verbose=1,\n",
        "                     validation_data=(x_test, y_test),\n",
        "                     shuffle=False)\n",
        "\n",
        "        scaled_scores_lstm = lstm_model.predict(x_test, batch_size=lstm_params['batch_size']).reshape(-1) * 2 - 1\n",
        "        lstm_sigma = np.append(lstm_sigma, get_sigma(scaled_scores_lstm, test_returns, test_dates))\n",
        "\n",
        "        curr_stack_features = np.concatenate([scaled_scores_lstm.reshape(-1,1), scaled_scores_lgbm.reshape(-1,1)], axis=1)\n",
        "        stack_train_features = np.concatenate([stack_train_features,curr_stack_features], axis=0)\n",
        "        stack_train_y = np.concatenate([stack_train_y,y_test], axis=0)\n",
        "\n",
        "      else:\n",
        "        \n",
        "        lstm_model.fit(x_train,\n",
        "                     y_train,\n",
        "                     batch_size=lstm_params['batch_size'],\n",
        "                     epochs= lstm_params['epochs'],\n",
        "                     verbose=1,\n",
        "                     validation_data=(x_val, y_val),\n",
        "                     shuffle=False)\n",
        "        \n",
        "        scaled_val_scores_lstm = lstm_model.predict(x_val, batch_size=lstm_params['batch_size']).reshape(-1) * 2 - 1\n",
        "        scaled_scores_lstm = lstm_model.predict(x_test, batch_size=lstm_params['batch_size']).reshape(-1) * 2 - 1\n",
        "        lstm_sigma = np.append(lstm_sigma, get_sigma(scaled_val_scores_lstm, val_returns, val_dates))\n",
        "\n",
        "        curr_stack_features = np.concatenate([scaled_scores_lstm.reshape(-1,1), scaled_scores_lgbm.reshape(-1,1)], axis=1)\n",
        "        stack_test_features = np.concatenate([stack_test_features,curr_stack_features], axis=0)\n",
        "        curr_val_features = np.concatenate([scaled_val_scores_lstm.reshape(-1,1), scaled_val_scores_lgbm.reshape(-1,1)], axis=1)\n",
        "        stack_val_features = np.concatenate([stack_val_features,curr_val_features], axis=0)\n",
        "        \n",
        "    else:\n",
        "      \n",
        "      # LGBM model\n",
        "\n",
        "      d_train = lgb.Dataset(lgbm_train, label=y_train)\n",
        "\n",
        "      lgbmodel = lgb.train(params, d_train, 100)\n",
        "      \n",
        "      scaled_val_scores_lgbm = lgbmodel.predict(lgbm_val, batch_size=252).reshape(-1) * 2 - 1\n",
        "      scaled_scores_lgbm = lgbmodel.predict(lgbm_test, batch_size=252).reshape(-1) * 2 - 1\n",
        "      lgbm_sigma = np.append(lgbm_sigma, get_sigma(scaled_scores_lgbm, test_returns, test_dates))\n",
        "      \n",
        "      # LSTM model\n",
        "      \n",
        "      if i != 5:\n",
        "\n",
        "        lstm_model.fit(x_train,\n",
        "               y_train,\n",
        "               batch_size=lstm_params['batch_size'],\n",
        "               epochs=lstm_params['epochs'],\n",
        "               verbose=1,\n",
        "               validation_data=(x_test, y_test),\n",
        "               shuffle=False)\n",
        "\n",
        "        scaled_scores_lstm = lstm_model.predict(x_test, batch_size=lstm_params['batch_size']).reshape(-1) * 2 - 1\n",
        "        lstm_sigma = np.append(lstm_sigma, get_sigma(scaled_scores_lstm, test_returns, test_dates))\n",
        "      \n",
        "        curr_stack_features = np.concatenate([x_test[:,0,(x_test.shape[2]-len(second_level_features)):(x_test.shape[2])], scaled_scores_lstm.reshape(-1,1), scaled_scores_lgbm.reshape(-1,1)], axis=1)\n",
        "        stack_train_features = np.concatenate([stack_train_features,curr_stack_features], axis=0)\n",
        "        stack_train_y = np.concatenate([stack_train_y,y_test], axis=0)\n",
        "\n",
        "      else:\n",
        "        \n",
        "        lstm_model.fit(x_train,\n",
        "               y_train,\n",
        "               batch_size=lstm_params['batch_size'],\n",
        "               epochs=lstm_params['epochs'],\n",
        "               verbose=1,\n",
        "               validation_data=(x_val, y_val),\n",
        "               shuffle=False)\n",
        "        \n",
        "        scaled_val_scores_lstm = lstm_model.predict(x_val, batch_size=lstm_params['batch_size']).reshape(-1) * 2 - 1\n",
        "        lstm_sigma = np.append(lstm_sigma, get_sigma(scaled_val_scores_lstm, val_returns, val_dates))\n",
        "        #scaled_scores_lstm = lstm_model.predict(x_test, batch_size=lstm_params['batch_size']).reshape(-1) * 2 - 1\n",
        "      \n",
        "        #curr_stack_features = np.concatenate([x_test[:,0,(x_test.shape[2]-len(second_level_features)):(x_test.shape[2])], scaled_scores_lstm.reshape(-1,1), scaled_scores_lgbm.reshape(-1,1)], axis=1)\n",
        "        #stack_test_features = np.concatenate([stack_test_features,curr_stack_features], axis=0)\n",
        "        curr_val_features = np.concatenate([x_val[:,0,(x_val.shape[2]-len(second_level_features)):(x_val.shape[2])], scaled_val_scores_lstm.reshape(-1,1), scaled_val_scores_lgbm.reshape(-1,1)], axis=1)\n",
        "        stack_val_features = np.concatenate([stack_val_features,curr_val_features], axis=0)\n",
        "             \n",
        "        \n",
        "  stack_train_features = reshape_LSTM_stack(stack_train_features)\n",
        "  stack_val_features = reshape_LSTM_stack(stack_val_features)\n",
        "  #stack_test_features = reshape_LSTM_stack(stack_test_features)\n",
        "  stack_train_y = reshape_LSTM_y(stack_train_y)\n",
        "  val_returns = reshape_LSTM_y(val_returns)\n",
        "  val_dates = reshape_LSTM_y(val_dates)\n",
        "  #test_returns = reshape_LSTM_y(test_returns)\n",
        "  #test_dates = reshape_LSTM_y(test_dates)\n",
        "\n",
        "  # tweak to match with batch_size\n",
        "  train_until = stack_train_features.shape[0] - stack_train_features.shape[0] % lstm_params['batch_size']\n",
        "  val_until = stack_val_features.shape[0] - stack_val_features.shape[0] % lstm_params['batch_size']\n",
        "  #test_until = stack_test_features.shape[0] - stack_test_features.shape[0] % lstm_params['batch_size']\n",
        "\n",
        "  stack_train_features = stack_train_features[:train_until]\n",
        "  stack_train_y = stack_train_y[:train_until]\n",
        "  stack_val_features = stack_val_features[:val_until]\n",
        "  val_returns = val_returns[:val_until]\n",
        "  val_dates = val_dates[:val_until]\n",
        "  #stack_test_features = stack_test_features[:test_until]\n",
        "  #test_returns = test_returns[:test_until]\n",
        "  #test_dates = test_dates[:test_until]\n",
        "\n",
        "  np.random.seed(1)\n",
        "  train_shuffle = np.random.permutation(range(stack_train_features.shape[0]))\n",
        "  val_shuffle = np.random.permutation(range(stack_val_features.shape[0]))\n",
        "  #test_shuffle = np.random.permutation(range(stack_test_features.shape[0]))\n",
        "  stack_train_features, stack_train_y = stack_train_features[train_shuffle], stack_train_y[train_shuffle]\n",
        "  stack_val_features, val_returns, val_dates = stack_val_features[val_shuffle], val_returns[val_shuffle], val_dates[val_shuffle]\n",
        "  #stack_test_features, test_returns, test_dates = stack_test_features[test_shuffle], test_returns[test_shuffle], test_dates[test_shuffle]\n",
        "\n",
        "  lstm_stack_model = create_stack_model()\n",
        "\n",
        "  lstm_stack_model.fit(stack_train_features,\n",
        "               stack_train_y,\n",
        "               batch_size=lstm_params['batch_size'],\n",
        "               epochs=lstm_params['epochs'],\n",
        "               verbose=1,\n",
        "               validation_data=(stack_val_features, val_returns),\n",
        "               shuffle=False)\n",
        "\n",
        "  #Prediction\n",
        "  \n",
        "  scaled_scores_lstm = lstm_stack_model.predict(stack_val_features, batch_size=lstm_params['batch_size']).reshape(-1) * 2 - 1\n",
        "  #scaled_scores_lstm = lstm_stack_model.predict(stack_test_features, batch_size=lstm_params['batch_size']).reshape(-1) * 2 - 1\n",
        "\n",
        "  curr_sigma_score = get_sigma(scaled_scores_lstm, val_returns, val_dates)\n",
        "  sigma_score = np.append(sigma_score, curr_sigma_score)\n",
        "\n",
        "  classify = lambda x: 1 if x > 0 else 0\n",
        "  scaled_scores_binary = np.array([classify(i) for i in scaled_scores_lstm])\n",
        "  val_returns_binary = np.array([classify(i) for i in val_returns])\n",
        "  curr_accuracy_score = metrics.accuracy_score(val_returns_binary, scaled_scores_binary)\n",
        "  curr_confusion_matrix = metrics.confusion_matrix(val_returns_binary, scaled_scores_binary)\n",
        "  accuracy_score = np.append(accuracy_score, curr_accuracy_score)\n",
        "  confusion_matrix = np.append(confusion_matrix, curr_confusion_matrix)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 22932 samples, validate on 22680 samples\n",
            "Epoch 1/2\n",
            "22932/22932 [==============================] - 4s 155us/step - loss: 0.6673 - acc: 0.5910 - val_loss: 0.7453 - val_acc: 0.5039\n",
            "Epoch 2/2\n",
            "22932/22932 [==============================] - 2s 109us/step - loss: 0.6521 - acc: 0.6195 - val_loss: 0.7560 - val_acc: 0.4987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 65772 samples, validate on 22428 samples\n",
            "Epoch 1/2\n",
            "65772/65772 [==============================] - 7s 113us/step - loss: 0.6764 - acc: 0.5751 - val_loss: 0.6842 - val_acc: 0.5607\n",
            "Epoch 2/2\n",
            "65772/65772 [==============================] - 6s 95us/step - loss: 0.6659 - acc: 0.5930 - val_loss: 0.6817 - val_acc: 0.5691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 108864 samples, validate on 21672 samples\n",
            "Epoch 1/2\n",
            "108864/108864 [==============================] - 11s 98us/step - loss: 0.6730 - acc: 0.5820 - val_loss: 0.7324 - val_acc: 0.5385\n",
            "Epoch 2/2\n",
            "108864/108864 [==============================] - 10s 88us/step - loss: 0.6621 - acc: 0.5992 - val_loss: 0.7595 - val_acc: 0.5348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 150948 samples, validate on 20916 samples\n",
            "Epoch 1/2\n",
            "150948/150948 [==============================] - 14s 95us/step - loss: 0.6713 - acc: 0.5890 - val_loss: 0.7190 - val_acc: 0.4870\n",
            "Epoch 2/2\n",
            "150948/150948 [==============================] - 13s 86us/step - loss: 0.6592 - acc: 0.6079 - val_loss: 0.7227 - val_acc: 0.4961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 193788 samples, validate on 21420 samples\n",
            "Epoch 1/2\n",
            "193788/193788 [==============================] - 18s 94us/step - loss: 0.6757 - acc: 0.5753 - val_loss: 0.7016 - val_acc: 0.5258\n",
            "Epoch 2/2\n",
            "193788/193788 [==============================] - 17s 86us/step - loss: 0.6634 - acc: 0.5992 - val_loss: 0.7188 - val_acc: 0.5075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 236880 samples, validate on 107100 samples\n",
            "Epoch 1/2\n",
            "236880/236880 [==============================] - 24s 100us/step - loss: 0.6746 - acc: 0.5791 - val_loss: 0.7381 - val_acc: 0.5004\n",
            "Epoch 2/2\n",
            "236880/236880 [==============================] - 22s 94us/step - loss: 0.6632 - acc: 0.5971 - val_loss: 0.7504 - val_acc: 0.4961\n",
            "Train on 108864 samples, validate on 106848 samples\n",
            "Epoch 1/2\n",
            "108864/108864 [==============================] - 13s 118us/step - loss: 0.6921 - acc: 0.5167 - val_loss: 0.3789 - val_acc: 0.0000e+00\n",
            "Epoch 2/2\n",
            "108864/108864 [==============================] - 11s 104us/step - loss: 0.6905 - acc: 0.5277 - val_loss: 0.2499 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 22680 samples, validate on 22680 samples\n",
            "Epoch 1/2\n",
            "22680/22680 [==============================] - 4s 185us/step - loss: 0.6807 - acc: 0.5644 - val_loss: 0.6983 - val_acc: 0.5118\n",
            "Epoch 2/2\n",
            "22680/22680 [==============================] - 3s 110us/step - loss: 0.6723 - acc: 0.5828 - val_loss: 0.6994 - val_acc: 0.5228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 66528 samples, validate on 22428 samples\n",
            "Epoch 1/2\n",
            "66528/66528 [==============================] - 9s 132us/step - loss: 0.6678 - acc: 0.5907 - val_loss: 0.7038 - val_acc: 0.5467\n",
            "Epoch 2/2\n",
            "66528/66528 [==============================] - 7s 100us/step - loss: 0.6556 - acc: 0.6112 - val_loss: 0.7260 - val_acc: 0.5416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 110124 samples, validate on 22680 samples\n",
            "Epoch 1/2\n",
            "110124/110124 [==============================] - 12s 109us/step - loss: 0.6752 - acc: 0.5791 - val_loss: 0.7168 - val_acc: 0.5047\n",
            "Epoch 2/2\n",
            "110124/110124 [==============================] - 10s 89us/step - loss: 0.6664 - acc: 0.5954 - val_loss: 0.7185 - val_acc: 0.5038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 155232 samples, validate on 22176 samples\n",
            "Epoch 1/2\n",
            "155232/155232 [==============================] - 16s 102us/step - loss: 0.6800 - acc: 0.5657 - val_loss: 0.6818 - val_acc: 0.5640\n",
            "Epoch 2/2\n",
            "155232/155232 [==============================] - 14s 88us/step - loss: 0.6723 - acc: 0.5807 - val_loss: 0.6830 - val_acc: 0.5637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 199332 samples, validate on 22176 samples\n",
            "Epoch 1/2\n",
            "199332/199332 [==============================] - 20s 99us/step - loss: 0.6782 - acc: 0.5699 - val_loss: 0.6878 - val_acc: 0.5607\n",
            "Epoch 2/2\n",
            "199332/199332 [==============================] - 17s 87us/step - loss: 0.6700 - acc: 0.5866 - val_loss: 0.6939 - val_acc: 0.5587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 241164 samples, validate on 106848 samples\n",
            "Epoch 1/2\n",
            "241164/241164 [==============================] - 25s 105us/step - loss: 0.6760 - acc: 0.5752 - val_loss: 0.7435 - val_acc: 0.5019\n",
            "Epoch 2/2\n",
            "241164/241164 [==============================] - 23s 94us/step - loss: 0.6680 - acc: 0.5894 - val_loss: 0.7599 - val_acc: 0.5037\n",
            "Train on 111888 samples, validate on 106596 samples\n",
            "Epoch 1/2\n",
            "111888/111888 [==============================] - 14s 129us/step - loss: 0.6880 - acc: 0.5438 - val_loss: 0.8601 - val_acc: 0.0000e+00\n",
            "Epoch 2/2\n",
            "111888/111888 [==============================] - 12s 105us/step - loss: 0.6858 - acc: 0.5513 - val_loss: 0.7274 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 22176 samples, validate on 22176 samples\n",
            "Epoch 1/2\n",
            "22176/22176 [==============================] - 5s 238us/step - loss: 0.6780 - acc: 0.5641 - val_loss: 0.6744 - val_acc: 0.5919\n",
            "Epoch 2/2\n",
            "22176/22176 [==============================] - 2s 111us/step - loss: 0.6693 - acc: 0.5879 - val_loss: 0.6713 - val_acc: 0.5918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 66024 samples, validate on 22176 samples\n",
            "Epoch 1/2\n",
            "66024/66024 [==============================] - 9s 140us/step - loss: 0.6709 - acc: 0.5894 - val_loss: 0.6795 - val_acc: 0.5786\n",
            "Epoch 2/2\n",
            "66024/66024 [==============================] - 6s 94us/step - loss: 0.6522 - acc: 0.6129 - val_loss: 0.6947 - val_acc: 0.5676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 110628 samples, validate on 22680 samples\n",
            "Epoch 1/2\n",
            "110628/110628 [==============================] - 13s 120us/step - loss: 0.6754 - acc: 0.5746 - val_loss: 0.6809 - val_acc: 0.5677\n",
            "Epoch 2/2\n",
            "110628/110628 [==============================] - 10s 90us/step - loss: 0.6574 - acc: 0.6076 - val_loss: 0.6857 - val_acc: 0.5664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 154224 samples, validate on 22680 samples\n",
            "Epoch 1/2\n",
            "154224/154224 [==============================] - 17s 110us/step - loss: 0.6740 - acc: 0.5802 - val_loss: 0.6777 - val_acc: 0.5740\n",
            "Epoch 2/2\n",
            "154224/154224 [==============================] - 14s 88us/step - loss: 0.6609 - acc: 0.6020 - val_loss: 0.6823 - val_acc: 0.5660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 199080 samples, validate on 22932 samples\n",
            "Epoch 1/2\n",
            "199080/199080 [==============================] - 21s 106us/step - loss: 0.6729 - acc: 0.5796 - val_loss: 0.6793 - val_acc: 0.5669\n",
            "Epoch 2/2\n",
            "199080/199080 [==============================] - 18s 88us/step - loss: 0.6626 - acc: 0.5965 - val_loss: 0.6797 - val_acc: 0.5673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 242676 samples, validate on 103068 samples\n",
            "Epoch 1/2\n",
            "242676/242676 [==============================] - 27s 112us/step - loss: 0.6734 - acc: 0.5777 - val_loss: 0.7426 - val_acc: 0.5056\n",
            "Epoch 2/2\n",
            "242676/242676 [==============================] - 23s 96us/step - loss: 0.6637 - acc: 0.5951 - val_loss: 0.7527 - val_acc: 0.5033\n",
            "Train on 112392 samples, validate on 102816 samples\n",
            "Epoch 1/2\n",
            "112392/112392 [==============================] - 16s 140us/step - loss: 0.6849 - acc: 0.5510 - val_loss: 0.4748 - val_acc: 0.0000e+00\n",
            "Epoch 2/2\n",
            "112392/112392 [==============================] - 14s 126us/step - loss: 0.6764 - acc: 0.5714 - val_loss: 0.6265 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 21168 samples, validate on 21168 samples\n",
            "Epoch 1/2\n",
            "21168/21168 [==============================] - 6s 302us/step - loss: 0.6772 - acc: 0.5760 - val_loss: 0.7336 - val_acc: 0.4639\n",
            "Epoch 2/2\n",
            "21168/21168 [==============================] - 2s 113us/step - loss: 0.6529 - acc: 0.6156 - val_loss: 0.7521 - val_acc: 0.4679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 63000 samples, validate on 20664 samples\n",
            "Epoch 1/2\n",
            "63000/63000 [==============================] - 10s 163us/step - loss: 0.6713 - acc: 0.5790 - val_loss: 0.7011 - val_acc: 0.5153\n",
            "Epoch 2/2\n",
            "63000/63000 [==============================] - 6s 94us/step - loss: 0.6567 - acc: 0.6054 - val_loss: 0.6991 - val_acc: 0.5260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 104832 samples, validate on 20916 samples\n",
            "Epoch 1/2\n",
            "104832/104832 [==============================] - 14s 132us/step - loss: 0.6792 - acc: 0.5626 - val_loss: 0.6972 - val_acc: 0.5370\n",
            "Epoch 2/2\n",
            "104832/104832 [==============================] - 9s 90us/step - loss: 0.6607 - acc: 0.5973 - val_loss: 0.6989 - val_acc: 0.5501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 146916 samples, validate on 21420 samples\n",
            "Epoch 1/2\n",
            "146916/146916 [==============================] - 18s 121us/step - loss: 0.6748 - acc: 0.5760 - val_loss: 0.6350 - val_acc: 0.6478\n",
            "Epoch 2/2\n",
            "146916/146916 [==============================] - 13s 89us/step - loss: 0.6595 - acc: 0.6008 - val_loss: 0.6346 - val_acc: 0.6447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 188496 samples, validate on 20412 samples\n",
            "Epoch 1/2\n",
            "188496/188496 [==============================] - 21s 114us/step - loss: 0.6663 - acc: 0.5903 - val_loss: 0.7503 - val_acc: 0.5102\n",
            "Epoch 2/2\n",
            "188496/188496 [==============================] - 17s 89us/step - loss: 0.6524 - acc: 0.6108 - val_loss: 0.7720 - val_acc: 0.5134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 225792 samples, validate on 104580 samples\n",
            "Epoch 1/2\n",
            "225792/225792 [==============================] - 29s 130us/step - loss: 0.6716 - acc: 0.5821 - val_loss: 0.7432 - val_acc: 0.5046\n",
            "Epoch 2/2\n",
            "225792/225792 [==============================] - 22s 98us/step - loss: 0.6595 - acc: 0.6013 - val_loss: 0.7470 - val_acc: 0.5027\n",
            "Train on 104328 samples, validate on 104328 samples\n",
            "Epoch 1/2\n",
            "104328/104328 [==============================] - 17s 158us/step - loss: 0.6885 - acc: 0.5394 - val_loss: 0.6964 - val_acc: 0.0000e+00\n",
            "Epoch 2/2\n",
            "104328/104328 [==============================] - 11s 110us/step - loss: 0.6821 - acc: 0.5597 - val_loss: 1.0799 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 23688 samples, validate on 22932 samples\n",
            "Epoch 1/2\n",
            "23688/23688 [==============================] - 8s 333us/step - loss: 0.6554 - acc: 0.6113 - val_loss: 0.7147 - val_acc: 0.5218\n",
            "Epoch 2/2\n",
            "23688/23688 [==============================] - 3s 113us/step - loss: 0.6324 - acc: 0.6466 - val_loss: 0.7295 - val_acc: 0.5230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 68040 samples, validate on 23436 samples\n",
            "Epoch 1/2\n",
            "68040/68040 [==============================] - 12s 174us/step - loss: 0.6870 - acc: 0.5420 - val_loss: 0.7043 - val_acc: 0.4657\n",
            "Epoch 2/2\n",
            "68040/68040 [==============================] - 7s 97us/step - loss: 0.6775 - acc: 0.5692 - val_loss: 0.7170 - val_acc: 0.4746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 113148 samples, validate on 22932 samples\n",
            "Epoch 1/2\n",
            "113148/113148 [==============================] - 16s 141us/step - loss: 0.6832 - acc: 0.5556 - val_loss: 0.6854 - val_acc: 0.5678\n",
            "Epoch 2/2\n",
            "113148/113148 [==============================] - 10s 92us/step - loss: 0.6743 - acc: 0.5760 - val_loss: 0.6952 - val_acc: 0.5542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 156996 samples, validate on 22428 samples\n",
            "Epoch 1/2\n",
            "156996/156996 [==============================] - 20s 127us/step - loss: 0.6788 - acc: 0.5683 - val_loss: 0.7274 - val_acc: 0.5076\n",
            "Epoch 2/2\n",
            "156996/156996 [==============================] - 14s 91us/step - loss: 0.6710 - acc: 0.5819 - val_loss: 0.7313 - val_acc: 0.4959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 201600 samples, validate on 22176 samples\n",
            "Epoch 1/2\n",
            "201600/201600 [==============================] - 24s 119us/step - loss: 0.6778 - acc: 0.5675 - val_loss: 0.6880 - val_acc: 0.5726\n",
            "Epoch 2/2\n",
            "201600/201600 [==============================] - 18s 90us/step - loss: 0.6636 - acc: 0.5939 - val_loss: 0.6976 - val_acc: 0.5508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: Mean of empty slice\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 245952 samples, validate on 114660 samples\n",
            "Epoch 1/2\n",
            "245952/245952 [==============================] - 31s 124us/step - loss: 0.6780 - acc: 0.5692 - val_loss: 0.7345 - val_acc: 0.4991\n",
            "Epoch 2/2\n",
            "245952/245952 [==============================] - 24s 98us/step - loss: 0.6666 - acc: 0.5901 - val_loss: 0.7297 - val_acc: 0.4971\n",
            "Train on 113652 samples, validate on 114408 samples\n",
            "Epoch 1/2\n",
            "113652/113652 [==============================] - 19s 164us/step - loss: 0.6890 - acc: 0.5403 - val_loss: 0.5845 - val_acc: 0.0000e+00\n",
            "Epoch 2/2\n",
            "113652/113652 [==============================] - 13s 110us/step - loss: 0.6875 - acc: 0.5438 - val_loss: 0.6405 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yq7eK6AQmw4_",
        "colab_type": "code",
        "outputId": "0a9f88a0-05fa-43ed-b40b-661e68750e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "sigma_score"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.3962073 ,  0.15815547,  0.17446199,  0.10734467, -0.22639669])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "9tq8n6at6Sll",
        "colab_type": "code",
        "outputId": "34ee9a6c-a86d-48dd-d27a-a8f6a55198f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "accuracy_score"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.53579852, 0.50545987, 0.50256769, 0.49953033, 0.47877771])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "uS-s86q59tZs",
        "colab_type": "code",
        "outputId": "9fa55da3-66e6-471a-8231-a24ae121e5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.7194e+04, 7.5000e+01, 4.9524e+04, 5.5000e+01, 2.8510e+04,\n",
              "       2.5719e+04, 2.6997e+04, 2.5370e+04, 2.8485e+04, 2.4067e+04,\n",
              "       2.7077e+04, 2.3187e+04, 2.5357e+04, 2.5883e+04, 2.6330e+04,\n",
              "       2.6758e+04, 5.3421e+04, 1.2110e+03, 5.8421e+04, 1.3550e+03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "IynNYayAaa9A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reference Code"
      ]
    },
    {
      "metadata": {
        "id": "c6FfNKjxFD9m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# EDITABLE PARAMETERS\n",
        "# Read the documentation in the script head for more details\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "# length of input\n",
        "input_len = 1000\n",
        "\n",
        "# The window length of the moving average used to generate\n",
        "# the output from the input in the input/output pair used\n",
        "# to train the LSTM\n",
        "# e.g. if tsteps=2 and input=[1, 2, 3, 4, 5],\n",
        "#      then output=[1.5, 2.5, 3.5, 4.5]\n",
        "tsteps = 2\n",
        "\n",
        "# The input sequence length that the LSTM is trained on for each output point\n",
        "lahead = 10\n",
        "\n",
        "# training parameters passed to \"model.fit(...)\"\n",
        "batch_size = 1\n",
        "epochs = 10\n",
        "\n",
        "# ------------\n",
        "# MAIN PROGRAM\n",
        "# ------------\n",
        "\n",
        "print(\"*\" * 33)\n",
        "if lahead >= tsteps:\n",
        "    print(\"STATELESS LSTM WILL ALSO CONVERGE\")\n",
        "else:\n",
        "    print(\"STATELESS LSTM WILL NOT CONVERGE\")\n",
        "print(\"*\" * 33)\n",
        "\n",
        "np.random.seed(1986)\n",
        "\n",
        "print('Generating Data...')\n",
        "\n",
        "\n",
        "def gen_uniform_amp(amp=1, xn=10000):\n",
        "    \"\"\"Generates uniform random data between\n",
        "    -amp and +amp\n",
        "    and of length xn\n",
        "\n",
        "    Arguments:\n",
        "        amp: maximum/minimum range of uniform data\n",
        "        xn: length of series\n",
        "    \"\"\"\n",
        "    data_input = np.random.uniform(-1 * amp, +1 * amp, xn)\n",
        "    data_input = pd.DataFrame(data_input)\n",
        "    return data_input\n",
        "\n",
        "# Since the output is a moving average of the input,\n",
        "# the first few points of output will be NaN\n",
        "# and will be dropped from the generated data\n",
        "# before training the LSTM.\n",
        "# Also, when lahead > 1,\n",
        "# the preprocessing step later of \"rolling window view\"\n",
        "# will also cause some points to be lost.\n",
        "# For aesthetic reasons,\n",
        "# in order to maintain generated data length = input_len after pre-processing,\n",
        "# add a few points to account for the values that will be lost.\n",
        "to_drop = max(tsteps - 1, lahead - 1)\n",
        "data_input = gen_uniform_amp(amp=0.1, xn=input_len + to_drop)\n",
        "\n",
        "# set the target to be a N-point average of the input\n",
        "expected_output = data_input.rolling(window=tsteps, center=False).mean()\n",
        "\n",
        "# when lahead > 1, need to convert the input to \"rolling window view\"\n",
        "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html\n",
        "if lahead > 1:\n",
        "    data_input = np.repeat(data_input.values, repeats=lahead, axis=1)\n",
        "    data_input = pd.DataFrame(data_input)\n",
        "    for i, c in enumerate(data_input.columns):\n",
        "        data_input[c] = data_input[c].shift(i)\n",
        "\n",
        "# drop the nan\n",
        "expected_output = expected_output[to_drop:]\n",
        "data_input = data_input[to_drop:]\n",
        "\n",
        "print('Input shape:', data_input.shape)\n",
        "print('Output shape:', expected_output.shape)\n",
        "print('Input head: ')\n",
        "print(data_input.head())\n",
        "print('Output head: ')\n",
        "print(expected_output.head())\n",
        "print('Input tail: ')\n",
        "print(data_input.tail())\n",
        "print('Output tail: ')\n",
        "print(expected_output.tail())\n",
        "\n",
        "print('Plotting input and expected output')\n",
        "plt.plot(data_input[0][:10], '.')\n",
        "plt.plot(expected_output[0][:10], '-')\n",
        "plt.legend(['Input', 'Expected output'])\n",
        "plt.title('Input')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def create_model(stateful):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(20,\n",
        "              input_shape=(lahead, 1),\n",
        "              batch_size=batch_size,\n",
        "              stateful=stateful))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "print('Creating Stateful Model...')\n",
        "model_stateful = create_model(stateful=True)\n",
        "\n",
        "\n",
        "# split train/test data\n",
        "def split_data(x, y, ratio=0.8):\n",
        "    to_train = int(input_len * ratio)\n",
        "    # tweak to match with batch_size\n",
        "    to_train -= to_train % batch_size\n",
        "\n",
        "    x_train = x[:to_train]\n",
        "    y_train = y[:to_train]\n",
        "    x_test = x[to_train:]\n",
        "    y_test = y[to_train:]\n",
        "\n",
        "    # tweak to match with batch_size\n",
        "    to_drop = x.shape[0] % batch_size\n",
        "    if to_drop > 0:\n",
        "        x_test = x_test[:-1 * to_drop]\n",
        "        y_test = y_test[:-1 * to_drop]\n",
        "\n",
        "    # some reshaping\n",
        "    reshape_3 = lambda x: x.values.reshape((x.shape[0], x.shape[1], 1))\n",
        "    x_train = reshape_3(x_train)\n",
        "    x_test = reshape_3(x_test)\n",
        "\n",
        "    reshape_2 = lambda x: x.values.reshape((x.shape[0], 1))\n",
        "    y_train = reshape_2(y_train)\n",
        "    y_test = reshape_2(y_test)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = split_data(data_input, expected_output)\n",
        "print('x_train.shape: ', x_train.shape)\n",
        "print('y_train.shape: ', y_train.shape)\n",
        "print('x_test.shape: ', x_test.shape)\n",
        "print('y_test.shape: ', y_test.shape)\n",
        "\n",
        "print('Training')\n",
        "for i in range(epochs):\n",
        "    print('Epoch', i + 1, '/', epochs)\n",
        "    # Note that the last state for sample i in a batch will\n",
        "    # be used as initial state for sample i in the next batch.\n",
        "    # Thus we are simultaneously training on batch_size series with\n",
        "    # lower resolution than the original series contained in data_input.\n",
        "    # Each of these series are offset by one step and can be\n",
        "    # extracted with data_input[i::batch_size].\n",
        "    model_stateful.fit(x_train,\n",
        "                       y_train,\n",
        "                       batch_size=batch_size,\n",
        "                       epochs=1,\n",
        "                       verbose=1,\n",
        "                       validation_data=(x_test, y_test),\n",
        "                       shuffle=False)\n",
        "    model_stateful.reset_states()\n",
        "\n",
        "print('Predicting')\n",
        "predicted_stateful = model_stateful.predict(x_test, batch_size=batch_size)\n",
        "\n",
        "print('Creating Stateless Model...')\n",
        "model_stateless = create_model(stateful=False)\n",
        "\n",
        "print('Training')\n",
        "model_stateless.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    shuffle=False)\n",
        "\n",
        "print('Predicting')\n",
        "predicted_stateless = model_stateless.predict(x_test, batch_size=batch_size)\n",
        "\n",
        "# ----------------------------\n",
        "\n",
        "print('Plotting Results')\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(y_test)\n",
        "plt.title('Expected')\n",
        "plt.subplot(3, 1, 2)\n",
        "# drop the first \"tsteps-1\" because it is not possible to predict them\n",
        "# since the \"previous\" timesteps to use do not exist\n",
        "plt.plot((y_test - predicted_stateful).flatten()[tsteps - 1:])\n",
        "plt.title('Stateful: Expected - Predicted')\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot((y_test - predicted_stateless).flatten())\n",
        "plt.title('Stateless: Expected - Predicted')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oo1x2aRs1jGh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Previous Code"
      ]
    },
    {
      "metadata": {
        "id": "1gkzZsrfmicW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigma_score(preds, valid_data):\n",
        "    df_time = valid_data.params['extra_time']\n",
        "    labels = valid_data.get_label()\n",
        "    \n",
        "    assert len(labels) == len(df_time)\n",
        "    \n",
        "    x_t = preds * labels\n",
        "\n",
        "    x_t_sum = x_t.groupby(df_time).sum()\n",
        "    score = x_t_sum.mean() / x_t_sum.std()\n",
        "    return 'sigma_score', score, True\n",
        "\n",
        "\n",
        "def sigma_score_plain(preds, labels, ds_time):\n",
        "    x_t = preds * labels\n",
        "    x_t_sum = x_t.groupby(ds_time.values).sum()\n",
        "    score = x_t_sum.mean() / x_t_sum.std()\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G8H9BlEymoiM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lgb_params = dict(\n",
        "    objective = 'regression_l1',\n",
        "    learning_rate = 0.1,\n",
        "    num_leaves = 12,\n",
        "    max_depth = 50,\n",
        "#     min_data_in_leaf = 1000,\n",
        "#     min_sum_hessian_in_leaf = 10,\n",
        "    bagging_fraction = 0.75,\n",
        "    bagging_freq = 2,\n",
        "    feature_fraction = 0.5,\n",
        "    lambda_l1 = 0.0,\n",
        "    lambda_l2 = .1,\n",
        "    metric = 'l2', # bbb\n",
        "    seed = 42\n",
        ")\n",
        "\n",
        "# potential area for improvement\n",
        "\n",
        "\n",
        "class BaseModel():\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.xtr = None\n",
        "        self.ytr = None\n",
        "        self.xval = None\n",
        "        self.yval = None\n",
        "        self.lgb_params = lgb_params\n",
        "        self.learning_rate_decay_fn = learning_rate_power\n",
        "        \n",
        "    \n",
        "    \n",
        "    def fit(self, xtr, ytr):\n",
        "        raise Exception('Not implemented. Override this method.')\n",
        "    \n",
        "    \n",
        "    def predict(self, xval):\n",
        "        raise Exception('Not implemented. Override this method.')\n",
        "        \n",
        "\n",
        "\n",
        "class LGBBasicModel(BaseModel):\n",
        "    def __init__(self, ban_words=None):\n",
        "        self.categorical_cols = ['dayofweek', 'month']\n",
        "        self.lgb_params = lgb_params\n",
        "        self.remove_list = ['time', 'universe', 'returnsOpenNextMktres10', 'assetCode', 'assetName', 'headline']\n",
        "        self.ban_words = ban_words\n",
        "        \n",
        "\n",
        "    def fit_eval(self, xtr, ytr, xval, yval, num_rounds=None):\n",
        "        self.fit_full(xtr, ytr, num_rounds)\n",
        "        return self.predict(xval)\n",
        "        \n",
        "        \n",
        "    def _filter_regex(self, data):\n",
        "        return data\n",
        "    \n",
        "    \n",
        "    def predict(self, xval):\n",
        "        ls_to_drop = []\n",
        "            \n",
        "        for c in self.remove_list:\n",
        "            if c in xval.columns:\n",
        "                ls_to_drop.append(c)\n",
        "        xval = xval.drop(columns=ls_to_drop)\n",
        "            \n",
        "        xval = self._filter_regex(xval)\n",
        "        \n",
        "        xval = xval[self.train_cols]\n",
        "        return self.model.predict(xval)\n",
        "    \n",
        "    \n",
        "    def fit(self, xtr, ytr):\n",
        "        if self.ban_words is not None:\n",
        "            drop_list = []\n",
        "            for col in xtr.columns:\n",
        "                for ban_word in self.ban_words:\n",
        "                    if ban_word in col:\n",
        "                        drop_list.append(col)\n",
        "                        break\n",
        "            xtr = xtr.drop(columns=drop_list)\n",
        "            \n",
        "        # actual training and validation sets\n",
        "        xtr_, xval_, ytr_, yval_ = train_test_split(xtr, ytr, test_size=0.2, shuffle=False)\n",
        "        \n",
        "        valid_params = {\n",
        "            'extra_time': xval_['time'].factorize()[0]\n",
        "        }\n",
        "        \n",
        "        ls_to_drop = []\n",
        "        for col in self.remove_list:\n",
        "            if col in xtr_.columns:\n",
        "                ls_to_drop.append(col)\n",
        "        \n",
        "        xtr_ = xtr_.drop(columns=ls_to_drop)\n",
        "        xval_ = xval_.drop(columns=ls_to_drop)\n",
        "        \n",
        "        xtr_ = self._filter_regex(xtr_)\n",
        "        xval_ = self._filter_regex(xval_)\n",
        "        \n",
        "        train_cols = xtr_.columns.tolist()\n",
        "        \n",
        "        # Note: y data is expected to be a pandas Series, as we will use its group_by function in `sigma_score`\n",
        "        dtrain = lgb.Dataset(xtr_.values, ytr_, feature_name=train_cols, categorical_feature=self.categorical_cols, free_raw_data=False)\n",
        "        dvalid = lgb.Dataset(xval_.values, yval_, feature_name=train_cols, categorical_feature=self.categorical_cols, free_raw_data=False)\n",
        "        dvalid.params = valid_params\n",
        "        evals_result = {}\n",
        "        m = lgb.train(lgb_params, dtrain, num_boost_round=1000, valid_sets=(dvalid,), valid_names=('valid',), verbose_eval=25,\n",
        "                      early_stopping_rounds=100, evals_result=evals_result)\n",
        "        self.train_cols = train_cols\n",
        "        self.model = m\n",
        "        self.evals_result = evals_result\n",
        "    \n",
        "    \n",
        "    def fit_full(self, xtr, ytr, num_rounds=None):\n",
        "        if self.ban_words is not None:\n",
        "            drop_list = []\n",
        "            for col in xtr.columns:\n",
        "                for ban_word in self.ban_words:\n",
        "                    if ban_word in col:\n",
        "                        drop_list.append(col)\n",
        "                        break\n",
        "            xtr = xtr.drop(columns=drop_list)\n",
        "        \n",
        "        if num_rounds is None:\n",
        "            df_result = pd.DataFrame(self.evals_result['valid'])\n",
        "            num_rounds = df_result['l2'].argmax()+1\n",
        "        \n",
        "        ls_to_drop = []\n",
        "        for col in self.remove_list:\n",
        "            if col in xtr.columns:\n",
        "                ls_to_drop.append(col)\n",
        "        \n",
        "        xtr = xtr.drop(columns=ls_to_drop)\n",
        "        xtr = self._filter_regex(xtr)\n",
        "        \n",
        "        train_cols = xtr.columns.tolist()\n",
        "        dtrain = lgb.Dataset(xtr.values, ytr, feature_name=train_cols, categorical_feature=self.categorical_cols, free_raw_data=False)\n",
        "        \n",
        "        m = lgb.train(self.lgb_params, dtrain, num_boost_round=num_rounds)\n",
        "        self.train_cols = train_cols\n",
        "        self.model = m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cTr0_oXisqGD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "def get_stack_data(models):\n",
        "#     df_xtr = pd.read_hdf('df_roll.h5', 'data')\n",
        "#     df_xtr = pd.read_pickle('df_roll.p')\n",
        "#     df_xtr = df_xtr.drop(columns='headline')\n",
        "    \n",
        "    global df_xtr\n",
        "    \n",
        "    arr_dates = df_xtr['time'].unique()\n",
        "    dt_start = arr_dates[-(arr_dates.shape[0] // 504) * 504]\n",
        "    \n",
        "    df_xtr = df_xtr[df_xtr['time'] >= dt_start]\n",
        "    \n",
        "    target = df_xtr['returnsOpenNextMktres10'].copy()\n",
        "#     stack_data = stack_models(df_xtr, models)\n",
        "    \n",
        "    stack_data = df_xtr\n",
        "    \n",
        "    stack_data['sentimentPositive_outperform'] = stack_data['sentimentPositive_mean'] - stack_data['sentimentPositive_mean'].mean()\n",
        "    stack_data['sentimentNegative_outperform'] = stack_data['sentimentNegative_mean'] - stack_data['sentimentNegative_mean'].mean()\n",
        "#     stack_data['open_close_outperform'] = stack_data['open_close'] - stack_data['open_close'].mean()\n",
        "#     stack_data['returnsOpenPrevMktres1_outperform'] = stack_data['returnsOpenPrevMktres1'] - stack_data['returnsOpenPrevMktres1'].mean()\n",
        "#     stack_data['returnsOpenPrevMktres10_outperform'] = stack_data['returnsOpenPrevMktres10'] - stack_data['returnsOpenPrevMktres10'].mean()\n",
        "\n",
        "#     stack_data.to_hdf('stack_data.h5', 'data')\n",
        "#     stack_data.to_pickle('stack_data.p')\n",
        "#     return stack_data, target\n",
        "    return stack_data\n",
        "\n",
        "with multiprocessing.Pool(1) as pool:\n",
        "    df_stack = pool.map(get_stack_data, [None])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laupIRa4q-6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cv_stack(X, model, k=5, seq=True, cv_type='model'):\n",
        "    if seq:\n",
        "        k += 1\n",
        "        breakpoints = [int(float(X.shape[0])*i/float(k)) for i in range(1, k)] + [X.shape[0]]\n",
        "    else:\n",
        "        breakpoints = [int(float(X.shape[0])*i/float(k)) for i in range(k)] + [X.shape[0]]\n",
        "    X = X.set_index('time')\n",
        "    y = X['returnsOpenNextMktres10']\n",
        "    X = X.drop(columns=['returnsOpenNextMktres10'])\n",
        "    res = []\n",
        "    \n",
        "    for i in range(len(breakpoints)-1):\n",
        "        # skip to last round (remove)\n",
        "        if i+1 < len(breakpoints)-1:\n",
        "            continue\n",
        "            \n",
        "        p1, p2 = breakpoints[i], breakpoints[i+1]\n",
        "        dt1, dt2 = X.index[p1], X.index[p2] if p2 < X.shape[0] else None\n",
        "        \n",
        "        dt1, dt2 = pd.to_datetime(dt1), pd.to_datetime(dt2)\n",
        "        X_train = X[:dt1 - dt.timedelta(days=1)].reset_index()\n",
        "        y_train = y[:dt1 - dt.timedelta(days=1)]\n",
        "        X_test = X[dt1:dt2].reset_index()\n",
        "        y_test = y[dt1:dt2]\n",
        "        ds_time = X[dt1:dt2].index\n",
        "        \n",
        "        \n",
        "        print('Fold %d (%s to %s)' % (i+1, dt1, dt2))\n",
        "        if seq:\n",
        "            if cv_type == 'model':\n",
        "                model.fit_full(X_train, y_train, num_rounds=200)\n",
        "                preds = model.predict(X_test)\n",
        "            elif cv_type == 'average':\n",
        "                preds = X_test.mean(axis=1)\n",
        "            elif cv_type == 'majority':\n",
        "                preds = []\n",
        "                for row in X_test.values:\n",
        "                    if (row > 0).sum() > X.shape[1] / 2:\n",
        "                        preds.append(row[row>0].mean())\n",
        "                    else:\n",
        "                        preds.append(row[row<=0].mean())\n",
        "            else:\n",
        "                raise Exception('Unsupported')\n",
        "            score = sigma_score_plain(np.array(preds), y_test, ds_time)\n",
        "            res.append(score)\n",
        "        else:\n",
        "            raise Exception('Not supported')\n",
        "            arr_flags = (np.arange(X.shape[0]) < dt1) | (np.arange(X.shape[0]) >= dt2)\n",
        "            res.append(fit_val\n",
        "                       (X[arr_flags], y[arr_flags], X.iloc[dt1:dt2], y.iloc[dt1:dt2]))\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEb6eckNsQQM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "cv_results = cv_stack(df_stack, LGBBasicModel(), cv_type='model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GevLPKxl3092",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cv_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7zoXG1zpopQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}